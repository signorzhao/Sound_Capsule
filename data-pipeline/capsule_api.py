"""
Synesth èƒ¶å›Šç³»ç»Ÿ Flask API æœåŠ¡å™¨

æä¾›èƒ¶å›Šç®¡ç†çš„ RESTful API æ¥å£
"""

import os
import sys
import json
import uuid
import subprocess
import argparse
import logging
import sqlite3
from pathlib import Path
from datetime import datetime

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from dotenv import load_dotenv

from capsule_db import get_database
from auth import get_auth_manager
from sync_service import get_sync_service
from prism_version_manager import PrismVersionManager
import capsule_scanner
from supabase_client import get_supabase_client
from capsule_download_api import register_download_routes

# ML åŠŸèƒ½å¯é€‰å¯¼å…¥ï¼ˆéœ€è¦ numpy, sklearn, sentence-transformersï¼‰
try:
    from hybrid_embedding_service import get_hybrid_service
    ML_AVAILABLE = True
except ImportError as e:
    ML_AVAILABLE = False
    logging.warning(f"ML åŠŸèƒ½ä¸å¯ç”¨ï¼ˆç¼ºå°‘ä¾èµ–ï¼‰: {e}")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
logger = logging.getLogger(__name__)

# ============================================
# å‘½ä»¤è¡Œå‚æ•°è§£æ
# ============================================

def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°

    æ”¯æŒçš„å‚æ•°:
        --config-dir: é…ç½®ç›®å½•è·¯å¾„ï¼ˆç”± Rust ä¼ é€’ï¼‰
        --export-dir: å¯¼å‡ºç›®å½•è·¯å¾„ï¼ˆç”± Rust ä¼ é€’ï¼‰
        --resource-dir: èµ„æºç›®å½•è·¯å¾„ï¼ˆæ‰“åŒ…åä½¿ç”¨ï¼‰
        --port: API ç«¯å£ï¼ˆé»˜è®¤ 5002ï¼‰

    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°
    """
    parser = argparse.ArgumentParser(description='Sound Capsule API Server')

    parser.add_argument('--config-dir', type=str,
                        help='é…ç½®ç›®å½•è·¯å¾„')
    parser.add_argument('--export-dir', type=str,
                        help='å¯¼å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--resource-dir', type=str,
                        help='èµ„æºç›®å½•è·¯å¾„ï¼ˆæ‰“åŒ…åï¼‰')
    parser.add_argument('--port', type=int, default=5002,
                        help='API æœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤ 5002ï¼‰')

    return parser.parse_args()

# è§£æå‘½ä»¤è¡Œå‚æ•°
ARGS = parse_arguments()

# ============================================
# è·¯å¾„åˆå§‹åŒ– - ğŸ”´ æ¶æ„é“å¾‹ï¼šç¦æ­¢è·¯å¾„çŒœæµ‹
# ============================================

# å¼ºåˆ¶æ£€æŸ¥å¿…éœ€å‚æ•°
if not ARGS.config_dir or not ARGS.export_dir:
    print("\n" + "=" * 60)
    print("âŒ é”™è¯¯ï¼šç¼ºå°‘å¿…éœ€çš„å‘½ä»¤è¡Œå‚æ•°")
    print("=" * 60)
    print("Sound Capsule å¿…é¡»ç”± Tauri å¯åŠ¨å¹¶ä¼ é€’ä»¥ä¸‹å‚æ•°ï¼š")
    print("  --config-dir  : é…ç½®ç›®å½•è·¯å¾„")
    print("  --export-dir  : å¯¼å‡ºç›®å½•è·¯å¾„")
    print("  --resource-dir: èµ„æºç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¼€å‘ç¯å¢ƒå¯çœç•¥ï¼‰")
    print("\nè¿™æ˜¯æ¶æ„é“å¾‹ï¼šPython åç«¯ä¸¥ç¦è‡ªè¡ŒçŒœæµ‹è·¯å¾„ã€‚")
    print("å¦‚æœä½ åœ¨å¼€å‘ç¯å¢ƒä¸­ç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œè¯·ä½¿ç”¨ï¼š")
    print("  python capsule_api.py --config-dir <path> --export-dir <path>")
    print("=" * 60 + "\n")
    sys.exit(1)

# èµ„æºç›®å½•ï¼šæ‰“åŒ…ç¯å¢ƒç”± Tauri ä¼ é€’ï¼Œå¼€å‘ç¯å¢ƒä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
RESOURCE_DIR = Path(ARGS.resource_dir) if ARGS.resource_dir else Path(__file__).parent

# ============================================
# åˆå§‹åŒ–ç»Ÿä¸€è·¯å¾„ç®¡ç†å™¨ï¼ˆå¿…é¡»åœ¨ä»»ä½•å…¶ä»–æ¨¡å—å¯¼å…¥ä¹‹å‰ï¼‰
# ============================================
from common import PathManager

PathManager.initialize(
    config_dir=str(ARGS.config_dir),
    export_dir=str(ARGS.export_dir),
    resource_dir=str(RESOURCE_DIR)
)

# è·å–è·¯å¾„ç®¡ç†å™¨å®ä¾‹
pm = PathManager.get_instance()

# å‘åå…¼å®¹ï¼šè®¾ç½®æ—§çš„å…¨å±€å˜é‡ï¼ˆæ–°ä»£ç åº”è¯¥ä½¿ç”¨ pmï¼‰
CONFIG_DIR = pm.config_dir
EXPORT_DIR = pm.export_dir

# è®¾ç½®æ—¥å¿—æ–‡ä»¶
LOG_FILE = pm.get_config_file('export_debug.log')

def log_to_file(message):
    """å†™å…¥æ—¥å¿—åˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {message}\n")
    print(message)  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ‰“å°è·¯å¾„é…ç½®ä¿¡æ¯
print("\n" + "=" * 60)
print("ğŸ“‚ è·¯å¾„é…ç½®ï¼ˆç”± PathManager ç®¡ç†ï¼‰")
print("=" * 60)
print(f"  CONFIG_DIR: {pm.config_dir}")
print(f"  EXPORT_DIR: {pm.export_dir}")
print(f"  RESOURCE_DIR: {pm.resource_dir}")
print(f"  DB_PATH: {pm.db_path}")
print(f"  SCHEMA_PATH: {pm.schema_path}")
print(f"  LUA_SCRIPTS_DIR: {pm.lua_scripts_dir}")
print(f"  LOG_FILE: {LOG_FILE}")
print("=" * 60 + "\n")

# load_user_config å·²åœ¨ common.py ä¸­å®šä¹‰ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å®šä¹‰

def setup_export_environment():
    """
    è®¾ç½®å¯¼å‡ºç¯å¢ƒå˜é‡

    ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨çš„å¯¼å‡ºç›®å½•ï¼Œå¹¶è®¾ç½®ç¯å¢ƒå˜é‡ä¾› Lua è„šæœ¬ä½¿ç”¨
    """
    pm = PathManager.get_instance()
    export_dir = str(pm.export_dir)

    os.environ['SYNESTH_CAPSULE_OUTPUT'] = export_dir
    log_to_file(f"âœ… è®¾ç½®å¯¼å‡ºç›®å½•ç¯å¢ƒå˜é‡: {export_dir}")
    print(f"âœ… è®¾ç½®å¯¼å‡ºç›®å½•ç¯å¢ƒå˜é‡: {export_dir}")

    return export_dir

app = Flask(__name__)
# å…è®¸å‰ç«¯ (3000, 3002, 5173) å’Œ REAPER Web UI (9000) è®¿é—®
default_origins = 'http://localhost:3000,http://localhost:3002,http://localhost:5173,http://localhost:9000,http://198.18.0.1:9000'
cors_origins = os.getenv('CORS_ORIGINS', default_origins).split(',')

# å…è®¸æ‰€æœ‰æœ¬åœ°å¼€å‘ç«¯å£è®¿é—®
CORS(app, resources={r"/api/*": {
    "origins": "*",  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    "allow_headers": ["Content-Type", "Authorization"],
    "max_age": 3600,
    "supports_credentials": False  # ä¸ä½¿ç”¨å‡­è¯æ—¶å¯ä»¥æ”¾å®½é™åˆ¶
}})

# æ³¨å†Œä¸‹è½½ç›¸å…³è·¯ç”± (JIT å†³ç­–æµ)
register_download_routes(app)

# é…ç½®ï¼ˆä½¿ç”¨è·¯å¾„ç®¡ç†å™¨ï¼‰
DB_PATH = str(pm.db_path)  # æ•°æ®åº“è·¯å¾„ä»è·¯å¾„ç®¡ç†å™¨è·å–
REAPER_CAPSULE_PATH = Path(os.getenv('REAPER_SONIC_CAPSULE_PATH', '../Reaper_Sonic_Capsule'))

# ============================================
# ğŸš€ Blueprint æ³¨å†Œ (API Modularization - Phase G, Step 0)
# ============================================
logger.info("æ­£åœ¨æ³¨å†Œ API Blueprint æ¨¡å—...")

# å¯¼å…¥ Blueprint æ¨¡å—
from routes.sync_routes import sync_bp
from routes.library_routes import library_bp

# æ³¨å†ŒåŒæ­¥æ¨¡å—ï¼Œæ‰€æœ‰è·¯ç”±å‰ç¼€ä¸º /api/sync
app.register_blueprint(sync_bp, url_prefix='/api/sync')
logger.info("âœ… Sync Routes æ³¨å†Œ: /api/sync/*")

# æ³¨å†Œåº“æ¨¡å—ï¼Œæ‰€æœ‰è·¯ç”±å‰ç¼€ä¸º /api/capsules
app.register_blueprint(library_bp, url_prefix='/api/capsules')
logger.info("âœ… Library Routes æ³¨å†Œ: /api/capsules/*")

# ============================================
# Phase C1: æ£±é•œç‰ˆæœ¬ç®¡ç†å™¨åˆå§‹åŒ–
# ============================================
# ä½¿ç”¨ PathManager è·å–æ­£ç¡®çš„æ•°æ®åº“è·¯å¾„
from common import PathManager
pm = PathManager.get_instance()
prism_manager = PrismVersionManager(db_path=str(pm.db_path))
try:
    prism_manager.init_tables()
    logger.info("âœ… æ£±é•œç‰ˆæœ¬ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ æ£±é•œç‰ˆæœ¬ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

# é…ç½®ä¿¡æ¯å·²åœ¨ä¸Šæ–¹çš„ PathManager åˆå§‹åŒ–æ—¶æ‰“å°
# ä¸å†éœ€è¦é‡å¤æ‰“å°


# ============================================
# é”™è¯¯å¤„ç†
# ============================================

# ä» common æ¨¡å—å¯¼å…¥ APIError å’Œ init_paths
from common import APIError, init_paths

# ä¸ºå‘åå…¼å®¹ï¼ŒåŒæ­¥å…¨å±€è·¯å¾„å˜é‡ï¼ˆPathManager å·²åœ¨ä¸Šæ–¹åˆå§‹åŒ–ï¼‰
init_paths(str(CONFIG_DIR), str(EXPORT_DIR), str(RESOURCE_DIR))

@app.errorhandler(APIError)
def handle_api_error(error):
    """å¤„ç† API é”™è¯¯"""
    import traceback
    logger.error(f"API Error: {error.message}")
    logger.error(traceback.format_exc())
    response = jsonify({
        'success': False,
        'error': error.message
    })
    response.status_code = error.status_code
    return response


@app.errorhandler(Exception)
def handle_generic_error(error):
    """å¤„ç†é€šç”¨é”™è¯¯"""
    import traceback
    logger.error(f"Internal Server Error: {error}")
    logger.error(traceback.format_exc())
    print(f"æœåŠ¡å™¨é”™è¯¯: {error}")
    response = jsonify({
        'success': False,
        'error': 'å†…éƒ¨æœåŠ¡å™¨é”™è¯¯'
    })
    response.status_code = 500
    return response


# ============================================
# å·¥å…·å‡½æ•°
# ============================================

def find_reaper_executable():
    """
    æŸ¥æ‰¾ REAPER å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆè·¨å¹³å°ï¼‰
    
    ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„è·¯å¾„

    Returns:
        Path æˆ– None
    """
    import platform
    import shutil
    import json

    # 1. ä¼˜å…ˆè¯»å–ç”¨æˆ·é…ç½®çš„ REAPER è·¯å¾„
    try:
        system = platform.system()
        if system == "Darwin":
            config_path = Path.home() / "Library/Application Support/com.soundcapsule.app/config.json"
        elif system == "Windows":
            config_path = Path.home() / "AppData/Roaming/com.soundcapsule.app/config.json"
        else:
            config_path = Path.home() / ".config/com.soundcapsule.app/config.json"
        
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                reaper_path = config.get('reaper_path')
                if reaper_path:
                    reaper_exe = Path(reaper_path)
                    if reaper_exe.exists():
                        print(f"âœ“ ä½¿ç”¨ç”¨æˆ·é…ç½®çš„ REAPER è·¯å¾„: {reaper_exe}")
                        return reaper_exe
                    else:
                        print(f"âš ï¸ ç”¨æˆ·é…ç½®çš„ REAPER è·¯å¾„ä¸å­˜åœ¨: {reaper_path}")
    except Exception as e:
        print(f"âš ï¸ è¯»å– REAPER é…ç½®å¤±è´¥: {e}")

    # 2. é™çº§åˆ°é»˜è®¤è·¯å¾„
    system = platform.system()

    if system == "Darwin":  # macOS
        paths = [
            Path("/Applications/REAPER.app/Contents/MacOS/REAPER"),
            Path("/Applications/REAPER64.app/Contents/MacOS/REAPER"),
            Path.home() / "Applications/REAPER.app/Contents/MacOS/REAPER"
        ]
    elif system == "Windows":
        paths = [
            Path("C:/Program Files/REAPER (x64)/reaper.exe"),
            Path("C:/Program Files/REAPER/reaper.exe"),
            Path("C:/Program Files (x86)/REAPER/reaper.exe"),
            Path.home() / "AppData/Local/Programs/REAPER/reaper.exe"
        ]
    else:  # Linux
        reaper_in_path = shutil.which("reaper")
        if reaper_in_path:
            return Path(reaper_in_path)
        paths = [Path("/usr/bin/reaper")]

    for path in paths:
        if path.exists():
            print(f"âœ“ æ‰¾åˆ° REAPER: {path}")
            return path

    return None


# ============================================
# è®¤è¯ä¸­é—´ä»¶
# ============================================

def get_current_user():
    """
    ä»è¯·æ±‚ä¸­è·å–å½“å‰ç”¨æˆ·
    
    æ”¯æŒä¸¤ç§è®¤è¯æ–¹å¼ï¼š
    1. Supabase Authï¼štoken éªŒè¯åè¿”å› supabase_user_id
    2. æœ¬åœ°è®¤è¯ï¼štoken éªŒè¯åè¿”å› user_idï¼ˆæ•´æ•°ï¼‰

    Returns:
        ç”¨æˆ·ä¿¡æ¯å­—å…¸æˆ– None

    Raises:
        APIError: å¦‚æœè®¤è¯å¤±è´¥
    """
    auth_header = request.headers.get('Authorization')

    if not auth_header:
        return None  # æœªæä¾› Tokenï¼Œè¿”å› Noneï¼ˆå…è®¸åŒ¿åè®¿é—®ï¼‰

    try:
        # è§£æ Bearer token
        token = auth_header.split(' ')[1]
    except IndexError:
        raise APIError('Token æ ¼å¼é”™è¯¯', 401)

    # éªŒè¯ token
    auth_manager = get_auth_manager()
    payload = auth_manager.verify_access_token(token)

    if not payload:
        raise APIError('Token æ— æ•ˆæˆ–å·²è¿‡æœŸ', 401)

    # æ ¹æ® payload ç±»å‹è·å–ç”¨æˆ·ä¿¡æ¯
    user = None
    
    # ä¼˜å…ˆä½¿ç”¨ supabase_user_idï¼ˆSupabase Authï¼‰
    if 'supabase_user_id' in payload:
        user = auth_manager.get_user_by_supabase_id(payload['supabase_user_id'])
        
        # å¦‚æœæœ¬åœ°æ²¡æœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å› payload ä¸­çš„ä¿¡æ¯
        if not user:
            user = {
                'id': payload['supabase_user_id'],
                'supabase_user_id': payload['supabase_user_id'],
                'username': payload.get('username'),
                'email': payload.get('email'),
                'display_name': payload.get('username')
            }
    
    # é™çº§åˆ°æœ¬åœ° user_idï¼ˆæœ¬åœ°è®¤è¯ï¼‰
    elif 'user_id' in payload:
        user = auth_manager.get_user_by_id(payload['user_id'])

    if not user:
        raise APIError('ç”¨æˆ·ä¸å­˜åœ¨', 401)

    return user


def token_required(f):
    """
    Token è®¤è¯è£…é¥°å™¨

    ç”¨äºä¿æŠ¤éœ€è¦è®¤è¯çš„ç«¯ç‚¹
    """
    def decorated(*args, **kwargs):
        user = get_current_user()

        if not user:
            raise APIError('éœ€è¦è®¤è¯', 401)

        # å°†ç”¨æˆ·ä¿¡æ¯ä¼ é€’ç»™è§†å›¾å‡½æ•°
        return f(current_user=user, *args, **kwargs)

    # ä¿ç•™åŸå§‹å‡½æ•°çš„åç§°
    decorated.__name__ = f.__name__
    return decorated


# ============================================
# è®¤è¯ API ç«¯ç‚¹
# ============================================

@app.route('/api/auth/register', methods=['POST'])
def register():
    """
    ç”¨æˆ·æ³¨å†Œ

    è¯·æ±‚ä½“:
        {
            "username": "ç”¨æˆ·å",
            "email": "é‚®ç®±",
            "password": "å¯†ç "
        }

    å“åº”:
        {
            "success": true,
            "message": "æ³¨å†ŒæˆåŠŸ",
            "data": {
                "user": {...},
                "tokens": {
                    "access_token": "...",
                    "refresh_token": "...",
                    "expires_in": 1800
                }
            }
        }
    """
    try:
        data = request.get_json()

        # éªŒè¯å¿…å¡«å­—æ®µ
        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        username = data.get('username')
        email = data.get('email')
        password = data.get('password')

        if not all([username, email, password]):
            raise APIError('ç”¨æˆ·åã€é‚®ç®±å’Œå¯†ç ä¸èƒ½ä¸ºç©º', 400)

        # æ³¨å†Œç”¨æˆ·
        auth_manager = get_auth_manager()
        result = auth_manager.register_user(username, email, password)

        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        if 'user' in result and 'password_hash' in result['user']:
            del result['user']['password_hash']

        return jsonify({
            'success': True,
            'message': 'æ³¨å†ŒæˆåŠŸ',
            'data': result
        }), 201

    except ValueError as e:
        raise APIError(str(e), 400)
    except Exception as e:
        raise APIError(f'æ³¨å†Œå¤±è´¥: {e}', 500)


@app.route('/api/auth/login', methods=['POST'])
def login():
    """
    ç”¨æˆ·ç™»å½•

    è¯·æ±‚ä½“:
        {
            "login": "ç”¨æˆ·åæˆ–é‚®ç®±",
            "password": "å¯†ç "
        }

    å“åº”:
        {
            "success": true,
            "message": "ç™»å½•æˆåŠŸ",
            "data": {
                "user": {...},
                "tokens": {...}
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        login = data.get('login')
        password = data.get('password')

        if not all([login, password]):
            raise APIError('ç™»å½•å‡­è¯ä¸èƒ½ä¸ºç©º', 400)

        # ç™»å½•
        auth_manager = get_auth_manager()
        result = auth_manager.login_user(login, password)

        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        if 'user' in result and 'password_hash' in result['user']:
            del result['user']['password_hash']

        return jsonify({
            'success': True,
            'message': 'ç™»å½•æˆåŠŸ',
            'data': result
        })

    except ValueError as e:
        raise APIError(str(e), 401)
    except Exception as e:
        raise APIError(f'ç™»å½•å¤±è´¥: {e}', 500)


@app.route('/api/auth/refresh', methods=['POST'])
def refresh_token():
    """
    åˆ·æ–° Access Token

    è¯·æ±‚ä½“:
        {
            "refresh_token": "..."
        }

    å“åº”:
        {
            "success": true,
            "data": {
                "access_token": "...",
                "expires_in": 1800
            }
        }
    """
    try:
        data = request.get_json()

        if not data or not data.get('refresh_token'):
            raise APIError('refresh_token ä¸èƒ½ä¸ºç©º', 400)

        refresh_token = data['refresh_token']
        auth_manager = get_auth_manager()

        result = auth_manager.refresh_token(refresh_token)

        return jsonify({
            'success': True,
            'data': result
        })

    except ValueError as e:
        raise APIError(str(e), 401)
    except Exception as e:
        raise APIError(f'Token åˆ·æ–°å¤±è´¥: {e}', 500)


@app.route('/api/auth/logout', methods=['POST'])
def logout():
    """
    ç”¨æˆ·æ³¨é”€

    è¯·æ±‚ä½“:
        {
            "refresh_token": "..."
        }

    å“åº”:
        {
            "success": True,
            "message": "æ³¨é”€æˆåŠŸ"
        }
    """
    try:
        data = request.get_json()

        if not data or not data.get('refresh_token'):
            raise APIError('refresh_token ä¸èƒ½ä¸ºç©º', 400)

        refresh_token = data['refresh_token']
        auth_manager = get_auth_manager()

        auth_manager.logout_user(refresh_token)

        return jsonify({
            'success': True,
            'message': 'æ³¨é”€æˆåŠŸ'
        })

    except Exception as e:
        raise APIError(f'æ³¨é”€å¤±è´¥: {e}', 500)


@app.route('/api/auth/me', methods=['GET'])
@token_required
def get_current_user_info(current_user):
    """
    è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "user": {...}
            }
        }
    """
    return jsonify({
        'success': True,
        'data': {
            'user': current_user
        }
    })


@app.route('/api/auth/me', methods=['PUT'])
@token_required
def update_current_user_info(current_user):
    """
    æ›´æ–°å½“å‰ç”¨æˆ·ä¿¡æ¯

    éœ€è¦è®¤è¯

    è¯·æ±‚ä½“:
        {
            "display_name": "æ˜¾ç¤ºåç§°",
            "bio": "ä¸ªäººç®€ä»‹",
            "avatar_url": "å¤´åƒ URL",
            "preferences": {...}
        }

    å“åº”:
        {
            "success": True,
            "message": "ç”¨æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ",
            "data": {
                "user": {...}
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        auth_manager = get_auth_manager()
        user = auth_manager.update_user_profile(current_user['id'], data)

        return jsonify({
            'success': True,
            'message': 'ç”¨æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ',
            'data': {
                'user': user
            }
        })

    except ValueError as e:
        raise APIError(str(e), 400)
    except Exception as e:
        raise APIError(f'æ›´æ–°ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}', 500)


@app.route('/api/auth/password', methods=['PUT'])
@token_required
def change_password(current_user):
    """
    ä¿®æ”¹å¯†ç 

    éœ€è¦è®¤è¯

    è¯·æ±‚ä½“:
        {
            "old_password": "æ—§å¯†ç ",
            "new_password": "æ–°å¯†ç "
        }

    å“åº”:
        {
            "success": True,
            "message": "å¯†ç ä¿®æ”¹æˆåŠŸ"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        old_password = data.get('old_password')
        new_password = data.get('new_password')

        if not all([old_password, new_password]):
            raise APIError('æ—§å¯†ç å’Œæ–°å¯†ç ä¸èƒ½ä¸ºç©º', 400)

        auth_manager = get_auth_manager()
        auth_manager.change_password(current_user['id'], old_password, new_password)

        return jsonify({
            'success': True,
            'message': 'å¯†ç ä¿®æ”¹æˆåŠŸ'
        })

    except ValueError as e:
        raise APIError(str(e), 400)
    except Exception as e:
        raise APIError(f'ä¿®æ”¹å¯†ç å¤±è´¥: {e}', 500)


# ============================================
# å…¶ä»– API ç«¯ç‚¹
# ============================================

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'success': True,
        'service': 'Synesth Capsule API',
        'version': '1.0.0',
        'timestamp': datetime.now().isoformat()
    })


@app.route('/api/debug-log', methods=['POST'])
def debug_log():
    """è°ƒè¯•æ—¥å¿—ç«¯ç‚¹ï¼ˆç”¨äºè¿½è¸ªåº”ç”¨é‡å¯é—®é¢˜ï¼‰"""
    try:
        data = request.get_json()
        message = data.get('message', 'NO MESSAGE')
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        import os
        from pathlib import Path
        
        log_dir = Path.home() / 'Library/Application Support/com.soundcapsule.app'
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / 'debug.log'
        
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
        log_entry = f"[{timestamp}] {message}\n"
        
        # è¿½åŠ æ—¥å¿—ï¼ˆå¦‚æœæ–‡ä»¶å¤ªå¤§åˆ™æ¸…ç©ºï¼‰
        if log_file.exists() and log_file.stat().st_size > 1024 * 1024:  # 1MB
            log_file.write_text(log_entry)
        else:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(log_entry)
        
        # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        logger.info(f"[DEBUG] {message}")
        
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"å†™å…¥è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/capsules', methods=['POST'])
def create_capsule():
    """
    åˆ›å»ºæ–°èƒ¶å›Š (æ‰‹åŠ¨åˆ›å»º)
    
    è¯·æ±‚ä½“:
        {
            "title": "èƒ¶å›Šåç§°",
            "description": "æè¿°",
            "type": "magic",
            "file_path": "è·¯å¾„/åˆ°/æ–‡ä»¶",
            ...
        }
    """
    try:
        data = request.get_json()
        logger.info(f"Received request to create capsule: {data}")
        
        if not data:
            raise APIError("Request body is empty", 400)
            
        uuid_str = data.get('uuid', str(uuid.uuid4()))
        name = data.get('title') or data.get('name', 'Untitled')
        
        # æ„é€ ç¬¦åˆæ•°æ®åº“è¦æ±‚çš„å­—å…¸
        capsule_data = {
            'uuid': uuid_str,
            'name': name,
            'project_name': data.get('project_name', name),
            'theme_name': data.get('theme_name', 'default'),
            'capsule_type': data.get('type', 'magic'),
            'file_path': data.get('file_path', ''),
            'preview_audio': data.get('preview_audio', ''),
            'rpp_file': data.get('rpp_file', ''),
            'metadata': data.get('metadata', {})
        }
        
        db = get_database()
        logger.info(f"Inserting capsule into database: {capsule_data}")
        capsule_id = db.insert_capsule(capsule_data)
        logger.info(f"Capsule created with ID: {capsule_id}")
        
        # å¦‚æœæœ‰æ ‡ç­¾æ•°æ®ï¼Œä¹Ÿå°è¯•æ·»åŠ 
        if 'tags' in data:
            tags = data['tags']
            # å°†ç®€å•å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼ (ç®€åŒ–å¤„ç†)
            formatted_tags = []
            for t in tags:
                if isinstance(t, str):
                    formatted_tags.append({
                        'lens': 'texture', # é»˜è®¤ lens
                        'word_id': f"tag_{uuid.uuid4().hex[:8]}", 
                        'word_cn': t
                    })
                elif isinstance(t, dict):
                    formatted_tags.append(t)
            
            if formatted_tags:
                db.add_capsule_tags(capsule_id, formatted_tags)
                
        # è¿”å›åˆ›å»ºçš„èƒ¶å›Šæ•°æ®
        return jsonify({
            'success': True,
            'message': 'Capsule created successfully',
            'capsule': {
                'id': capsule_id,
                **capsule_data
            }
        }), 201
        
    except Exception as e:
        import traceback
        logger.error(f"Failed to create capsule: {e}")
        logger.error(traceback.format_exc())
        raise APIError(f"Failed to create capsule: {str(e)}", 500)


# ============================================================
# âš ï¸  ä»¥ä¸‹è·¯ç”±å·²è¿ç§»åˆ° routes/library_routes.py Blueprint
# ============================================================
# GET /api/capsules - get_capsules (å·²è¿ç§»)
# GET /api/capsules/<int:capsule_id> - get_capsule (å·²è¿ç§»)
# DELETE /api/capsules/<int:capsule_id> - delete_capsule_api (å·²è¿ç§»)
# GET /api/capsules/<int:capsule_id>/tags - get_capsule_tags_api (å·²è¿ç§»)
# POST /api/capsules/<int:capsule_id>/tags - add_capsule_tags (å·²è¿ç§»)
# PUT /api/capsules/<int:capsule_id>/tags - replace_capsule_tags (å·²è¿ç§»)
# ============================================================

@app.route('/api/capsules/export', methods=['POST'])
def export_capsule():
    """
    å¯¼å‡ºèƒ¶å›Š

    Request Body:
        {
            "project_name": "é¡¹ç›®å",
            "theme_name": "ä¸»é¢˜å",
            "render_preview": true
        }

    Returns:
        {
            "success": true,
            "capsule_id": 123,
            "capsule_path": "/path/to/capsule"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError("è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º")

        project_name = data.get('project_name', '').strip()
        theme_name = data.get('theme_name', '').strip()
        render_preview = data.get('render_preview', True)

        if not project_name:
            raise APIError("é¡¹ç›®åä¸èƒ½ä¸ºç©º")

        if not theme_name:
            raise APIError("ä¸»é¢˜åä¸èƒ½ä¸ºç©º")

        # è°ƒç”¨ REAPER æ¡¥æ¥å™¨å¯¼å‡ºèƒ¶å›Š
        from exporters.reaper_bridge import ReaperBridge

        bridge = ReaperBridge(REAPER_CAPSULE_PATH, use_headless=True)

        result = bridge.export_capsule(
            project_name=project_name,
            theme_name=theme_name,
            render_preview=render_preview,
            output_dir=capsule_scanner.get_output_dir()  # ä½¿ç”¨ç”¨æˆ·é…ç½®çš„å¯¼å‡ºç›®å½•
        )

        if not result.get('success'):
            raise APIError(result.get('error', 'å¯¼å‡ºå¤±è´¥'), 500)

        # è¯»å–å¯¼å‡ºçš„å…ƒæ•°æ®
        capsule_path = Path(result.get('capsule_path'))
        metadata_file = capsule_path / "metadata.json"

        if not metadata_file.exists():
            raise APIError("å¯¼å‡ºæˆåŠŸä½†æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶", 500)

        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        # æ’å…¥æ•°æ®åº“
        # ä½¿ç”¨ç›¸å¯¹äºå¯¼å‡ºç›®å½•çš„è·¯å¾„
        capsule_data = {
            'uuid': metadata.get('id', str(uuid.uuid4())),
            'name': metadata.get('name', f"{project_name}_{theme_name}"),
            'project_name': project_name,
            'theme_name': theme_name,
            'capsule_type': 'magic',  # é»˜è®¤ä¸º magic
            'file_path': str(capsule_path.relative_to(capsule_scanner.get_output_dir())),
            'preview_audio': metadata.get('preview_audio'),
            'rpp_file': metadata.get('files', {}).get('project', 'source.rpp'),
            'metadata': {
                'bpm': metadata.get('info', {}).get('bpm'),
                'duration': metadata.get('info', {}).get('length'),
                'sample_rate': metadata.get('info', {}).get('sample_rate'),
                'plugin_count': metadata.get('plugins', {}).get('count'),
                'plugin_list': metadata.get('plugins', {}).get('list', []),
                'has_sends': metadata.get('routing_info', {}).get('has_sends'),
                'has_folder_bus': metadata.get('routing_info', {}).get('has_folder_bus'),
                'tracks_included': metadata.get('routing_info', {}).get('tracks_included')
            }
        }

        db = get_database()
        capsule_id = db.insert_capsule(capsule_data)

        # æ£€æµ‹æœ¬åœ° WAV æ–‡ä»¶å¹¶æ›´æ–° asset_status
        audio_folder = capsule_path / "Audio"
        if audio_folder.exists():
            wav_files = list(audio_folder.glob("*.wav"))
            if wav_files:
                # æœ‰ WAV æ–‡ä»¶ï¼Œæ›´æ–°ä¸º local çŠ¶æ€
                total_size = sum(f.stat().st_size for f in wav_files)
                db.connect()
                try:
                    cursor = db.conn.cursor()
                    cursor.execute("""
                        UPDATE capsules
                        SET asset_status = 'local',
                            local_wav_path = ?,
                            local_wav_size = ?
                        WHERE id = ?
                    """, (str(audio_folder), total_size, capsule_id))
                    db.conn.commit()
                    print(f"âœ“ èƒ¶å›Š {capsule_id} è®¾ç½®ä¸º local çŠ¶æ€ï¼ˆ{len(wav_files)} ä¸ª WAV æ–‡ä»¶ï¼‰")
                finally:
                    db.close()

        return jsonify({
            'success': True,
            'capsule_id': capsule_id,
            'capsule_path': str(capsule_path),
            'metadata': metadata
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"å¯¼å‡ºå¤±è´¥: {e}", 500)


# POST å’Œ PUT /api/capsules/<int:capsule_id>/tags å·²è¿ç§»åˆ° routes/library_routes.py

@app.route('/api/capsules/<int:capsule_id>/preview', methods=['GET'])
@app.route('/api/capsules/<int:capsule_id>/preview/<path:filename>', methods=['GET'])
def stream_preview(capsule_id, filename=None):
    """
    æµå¼ä¼ è¾“é¢„è§ˆéŸ³é¢‘

    æ”¯æŒä¸¤ç§æ ¼å¼:
    - /api/capsules/{id}/preview (ä½¿ç”¨æ•°æ®åº“ä¸­çš„æ–‡ä»¶å)
    - /api/capsules/{id}/preview/{filename} (ç›´æ¥æŒ‡å®šæ–‡ä»¶å)

    æ”¯æŒ Range è¯·æ±‚ï¼ˆå¯æ‹–åŠ¨è¿›åº¦æ¡ï¼‰
    """
    try:
        # å¯¼å…¥ scanner æ¨¡å—ä»¥è·å– OUTPUT_DIR
        import capsule_scanner

        db = get_database()
        capsule = db.get_capsule(capsule_id)

        if not capsule:
            raise APIError(f"èƒ¶å›Šä¸å­˜åœ¨: {capsule_id}", 404)

        # å¦‚æœæä¾›äº†æ–‡ä»¶åå‚æ•°ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨æ•°æ®åº“ä¸­çš„
        preview_audio = filename or capsule.get('preview_audio')

        if not preview_audio:
            raise APIError("é¢„è§ˆéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨", 404)

        # ä½¿ç”¨ get_output_dir()ï¼ˆç”¨æˆ·é…ç½®çš„å¯¼å‡ºç›®å½•ï¼‰è€Œä¸æ˜¯ CAPSULE_ROOT
        # capsule['file_path'] æ˜¯ç›¸å¯¹äº output_dir çš„è·¯å¾„
        output_dir = capsule_scanner.get_output_dir()
        preview_file = output_dir / capsule['file_path'] / preview_audio

        # è°ƒè¯•æ—¥å¿—
        print(f"ğŸ” [é¢„è§ˆéŸ³é¢‘] è°ƒè¯•ä¿¡æ¯:")
        print(f"  - output_dir: {output_dir}")
        print(f"  - output_dir (absolute): {output_dir.resolve()}")
        print(f"  - capsule['file_path']: {capsule['file_path']}")
        print(f"  - preview_audio: {preview_audio}")
        print(f"  - æ‹¼æ¥åçš„è·¯å¾„: {preview_file}")
        print(f"  - ç»å¯¹è·¯å¾„: {preview_file.resolve()}")
        print(f"  - æ–‡ä»¶å­˜åœ¨: {preview_file.exists()}")

        if not preview_file.exists():
            raise APIError(f"é¢„è§ˆéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {preview_audio}", 404)

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        preview_file = preview_file.resolve()

        return send_file(
            preview_file,
            mimetype='audio/ogg',
            as_attachment=False,
            conditional=True  # æ”¯æŒ Range è¯·æ±‚
        )

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å–é¢„è§ˆå¤±è´¥: {e}", 500)


@app.route('/api/capsules/<int:capsule_id>/metadata', methods=['GET'])
def get_capsule_metadata(capsule_id):
    """
    è·å–èƒ¶å›Šçš„ metadata.json å†…å®¹

    Returns:
        metadata å¯¹è±¡
    """
    try:
        # å¯¼å…¥ scanner æ¨¡å—ä»¥è·å– OUTPUT_DIR
        import capsule_scanner

        db = get_database()
        capsule = db.get_capsule(capsule_id)

        if not capsule:
            raise APIError(f"èƒ¶å›Šä¸å­˜åœ¨: {capsule_id}", 404)

        # ä½¿ç”¨ OUTPUT_DIRï¼ˆç”¨æˆ·é…ç½®çš„å¯¼å‡ºç›®å½•ï¼‰è€Œä¸æ˜¯ CAPSULE_ROOT
        metadata_file = capsule_scanner.get_output_dir() / capsule['file_path'] / 'metadata.json'

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»æ•°æ®åº“è·å– metadata
        if not metadata_file.exists():
            logger.info(f"[Metadata] metadata.json æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»æ•°æ®åº“è·å– metadata (èƒ¶å›Š ID: {capsule_id})")

            # ä» capsule.get_capsule() å·²ç»åŒ…å«äº† metadata
            if capsule.get('metadata'):
                return jsonify({
                    'success': True,
                    'metadata': capsule['metadata']
                })
            else:
                raise APIError("metadata.json æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ•°æ®åº“ä¸­æ—  metadata", 404)

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        metadata_file = metadata_file.resolve()

        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        return jsonify({
            'success': True,
            'metadata': metadata
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å– metadata å¤±è´¥: {e}", 500)


@app.route('/api/capsules/<int:capsule_id>/open', methods=['POST'])
def open_in_reaper(capsule_id):
    """
    åœ¨ REAPER ä¸­æ‰“å¼€èƒ¶å›Š

    Returns:
        {
            "success": true,
            "message": "å·²åœ¨ REAPER ä¸­æ‰“å¼€"
        }
    """
    try:
        # å¯¼å…¥ scanner æ¨¡å—ä»¥è·å– OUTPUT_DIR
        import capsule_scanner

        db = get_database()
        capsule = db.get_capsule(capsule_id)

        if not capsule:
            raise APIError(f"èƒ¶å›Šä¸å­˜åœ¨: {capsule_id}", 404)

        # è·å–æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†å¯èƒ½ä¸º None çš„æƒ…å†µ
        file_path = capsule.get('file_path') or capsule.get('name')
        rpp_filename = capsule.get('rpp_file')
        
        # å¦‚æœ rpp_file ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨èƒ¶å›Šåç§°æ„å»ºé»˜è®¤æ–‡ä»¶å
        if not rpp_filename:
            # å°è¯•æŸ¥æ‰¾ç›®å½•ä¸­çš„ .rpp æ–‡ä»¶
            capsule_dir = capsule_scanner.get_output_dir() / file_path
            if capsule_dir.exists():
                rpp_files = list(capsule_dir.glob("*.rpp"))
                if rpp_files:
                    rpp_filename = rpp_files[0].name
                else:
                    # ä½¿ç”¨é»˜è®¤å‘½åè§„åˆ™
                    rpp_filename = f"{capsule['name']}.rpp"
            else:
                rpp_filename = f"{capsule['name']}.rpp"
        
        if not file_path:
            raise APIError("èƒ¶å›Šè·¯å¾„ä¿¡æ¯ç¼ºå¤±", 400)

        # ä½¿ç”¨ OUTPUT_DIRï¼ˆç”¨æˆ·é…ç½®çš„å¯¼å‡ºç›®å½•ï¼‰è€Œä¸æ˜¯ CAPSULE_ROOT
        rpp_file = capsule_scanner.get_output_dir() / file_path / rpp_filename

        if not rpp_file.exists():
            raise APIError(f"RPP æ–‡ä»¶ä¸å­˜åœ¨: {rpp_file}", 404)

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        rpp_file = rpp_file.resolve()

        # æŸ¥æ‰¾ REAPER å¯æ‰§è¡Œæ–‡ä»¶
        reaper_exe = find_reaper_executable()

        if not reaper_exe:
            raise APIError("æ‰¾ä¸åˆ° REAPER å¯æ‰§è¡Œæ–‡ä»¶", 500)

        # å¯åŠ¨ REAPERï¼ˆæ–°å®ä¾‹ï¼‰
        import platform

        if platform.system() == "Darwin":  # macOS
            cmd = ["open", "-a", str(reaper_exe), str(rpp_file)]
            subprocess.run(cmd, check=True, capture_output=True)
        elif platform.system() == "Windows":
            # Windows ä¸Šç›´æ¥ç”¨ REAPER å¯æ‰§è¡Œæ–‡ä»¶æ‰“å¼€é¡¹ç›®
            subprocess.Popen([str(reaper_exe), str(rpp_file)], 
                           creationflags=subprocess.DETACHED_PROCESS | subprocess.CREATE_NEW_PROCESS_GROUP)
        else:  # Linux
            cmd = ["xdg-open", str(rpp_file)]
            subprocess.run(cmd, check=True, capture_output=True)

        return jsonify({
            'success': True,
            'message': f"å·²åœ¨ REAPER ä¸­æ‰“å¼€: {capsule['name']}"
        })

    except APIError:
        raise
    except subprocess.CalledProcessError as e:
        raise APIError(f"å¯åŠ¨ REAPER å¤±è´¥: {e}", 500)
    except Exception as e:
        raise APIError(f"æ‰“å¼€å¤±è´¥: {e}", 500)


# ============================================
# çœŸæ­£çš„ä¸€é”®å¯¼å‡º (åå°æ‰§è¡Œ REAPER)
# ============================================

@app.route('/api/capsules/auto-export', methods=['POST'])
def auto_export_api():
    """
    ä¸€é”®å¯¼å‡º: åœ¨åå°å¯åŠ¨ REAPER æ‰§è¡Œå¯¼å‡º,æ— éœ€ç”¨æˆ·æ‰‹åŠ¨æ“ä½œ

    è¯·æ±‚ä½“:
        {
            "project_name": "é¡¹ç›®å",
            "theme_name": "ä¸»é¢˜å",
            "render_preview": true
        }

    å“åº”:
        {
            "success": true,
            "capsule_name": "é¡¹ç›®å_ä¸»é¢˜å",
            "message": "å¯¼å‡ºæˆåŠŸ"
        }
    """
    try:
        from exporters.reaper_headless_export import quick_export

        data = request.get_json()

        project_name = data.get('project_name', '').strip()
        theme_name = data.get('theme_name', '').strip()
        render_preview = data.get('render_preview', True)

        if not project_name:
            raise APIError("é¡¹ç›®åä¸èƒ½ä¸ºç©º")

        if not theme_name:
            raise APIError("ä¸»é¢˜åä¸èƒ½ä¸ºç©º")

        # æ‰§è¡Œå¯¼å‡º
        print(f"\n{'='*50}")
        print(f"å¼€å§‹è‡ªåŠ¨å¯¼å‡º: {project_name}_{theme_name}")
        print(f"{'='*50}\n")

        result = quick_export(
            project_name=project_name,
            theme_name=theme_name,
            render_preview=render_preview
        )

        print(f"\n{'='*50}")
        print(f"å¯¼å‡ºç»“æœ: {result}")
        print(f"{'='*50}\n")

        if not result['success']:
            raise APIError(result.get('error', 'å¯¼å‡ºå¤±è´¥'))

        # å¯¼å‡ºæˆåŠŸå,è‡ªåŠ¨æ‰«æå¹¶å¯¼å…¥
        from capsule_scanner import scan_and_import_all
        imported = scan_and_import_all()

        return jsonify({
            'success': True,
            'capsule_name': result.get('capsule_name'),
            'message': 'å¯¼å‡ºæˆåŠŸ',
            'imported_count': len(imported),
            'auto_imported': imported
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è‡ªåŠ¨å¯¼å‡ºå¤±è´¥: {e}", 500)


# ============================================
# REAPER Web UI è¿œç¨‹è§¦å‘å¯¼å‡º (æ¨è!)
# ============================================

@app.route('/api/capsules/webui-export', methods=['OPTIONS', 'POST'])
def webui_export_api():
    """
    REAPER Web UI è¿œç¨‹è§¦å‘å¯¼å‡º

    ä½¿ç”¨ REAPER 7.0+ çš„ Web UI åŠŸèƒ½è¿›è¡Œè¿œç¨‹æ§åˆ¶

    è¯·æ±‚ä½“:
        {
            "project_name": "é¡¹ç›®å",
            "theme_name": "ä¸»é¢˜å",
            "render_preview": true,
            "webui_port": 9000  # å¯é€‰,é»˜è®¤ 9000
        }

    å“åº”:
        {
            "success": true,
            "capsule_name": "é¡¹ç›®å_ä¸»é¢˜å",
            "message": "å¯¼å‡ºæˆåŠŸ"
        }
    """
    # å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
        response.headers.add('Access-Control-Max-Age', '3600')
        return response

    try:
        from exporters.reaper_webui_export import quick_webui_export

        data = request.get_json()

        # è·å– capsule_type (å¯èƒ½æ˜¯ ID æ•°å­—æˆ–åç§°å­—ç¬¦ä¸²)
        capsule_type_input = data.get('capsule_type', 'magic')
        render_preview = data.get('render_preview', True)
        webui_port = data.get('webui_port', 9000)

        # å¦‚æœ capsule_type æ˜¯æ•°å­— IDï¼Œè½¬æ¢ä¸ºåç§°
        if isinstance(capsule_type_input, int):
            db = get_database()
            capsule_type_obj = db.get_capsule_type(capsule_type_input)
            if capsule_type_obj:
                capsule_type = capsule_type_obj.get('name', 'magic')
            else:
                capsule_type = 'magic'
        else:
            capsule_type = capsule_type_input

        # ä½¿ç”¨ capsule_type ä½œä¸º project_name å’Œ theme_name
        project_name = capsule_type
        theme_name = capsule_type

        # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
        log_to_file("=" * 80)
        log_to_file("ğŸš€ æ”¶åˆ°å¯¼å‡ºè¯·æ±‚")
        log_to_file(f"èƒ¶å›Šç±»å‹: {capsule_type}")
        log_to_file(f"æ¸²æŸ“é¢„è§ˆ: {render_preview}")
        log_to_file(f"æ¥æ”¶åˆ°çš„å®Œæ•´æ•°æ®: {data}")
        log_to_file("=" * 80)

        # è·å–å¯¼å‡ºç›®å½•
        # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ é€’çš„ export_dirï¼Œå¦åˆ™ä½¿ç”¨ setup_export_environment()
        export_dir = data.get('export_dir')
        if export_dir:
            log_to_file(f"âœ… ä½¿ç”¨å‰ç«¯ä¼ é€’çš„å¯¼å‡ºç›®å½•: {export_dir}")
            # è®¾ç½®ç¯å¢ƒå˜é‡ä¾› Lua è„šæœ¬ä½¿ç”¨
            os.environ['SYNESTH_CAPSULE_OUTPUT'] = export_dir

            # åŒæ—¶æ›´æ–°é…ç½®æ–‡ä»¶ï¼Œç¡®ä¿ä¸‹æ¬¡ä¸‹è½½æ—¶ä½¿ç”¨æ­£ç¡®çš„ç›®å½•
            try:
                from pathlib import Path

                # ä½¿ç”¨ä¸ capsule_scanner.py ç›¸åŒçš„é…ç½®æ–‡ä»¶è·¯å¾„
                home = Path.home()
                system = os.uname().sysname.lower() if hasattr(os, 'uname') else 'unknown'

                if 'darwin' in system:
                    # macOS
                    config_dir = home / 'Library/Application Support/com.soundcapsule.app'
                elif 'windows' in system or os.name == 'nt':
                    # Windows
                    appdata = os.environ.get('APPDATA', home / 'AppData/Roaming')
                    config_dir = Path(appdata) / 'com.soundcapsule.app'
                else:
                    # Linux
                    config_dir = home / '.config/com.soundcapsule.app'

                config_file = config_dir / 'config.json'

                # è¯»å–ç°æœ‰é…ç½®
                existing_config = {}
                if config_file.exists():
                    with open(config_file, 'r', encoding='utf-8') as f:
                        existing_config = json.load(f)

                # æ›´æ–°å¯¼å‡ºç›®å½•
                existing_config['export_dir'] = export_dir

                # ä¿å­˜é…ç½®
                config_file.parent.mkdir(parents=True, exist_ok=True)
                with open(config_file, 'w', encoding='utf-8') as f:
                    json.dump(existing_config, f, indent=2, ensure_ascii=False)

                logger.info(f"[CONFIG] âœ… å·²æ›´æ–°é…ç½®æ–‡ä»¶: {export_dir}")
            except Exception as e:
                logger.warning(f"[CONFIG] âš  æ›´æ–°é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        else:
            log_to_file(f"âš ï¸  å‰ç«¯æœªä¼ é€’ export_dirï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶")
            export_dir = setup_export_environment()

        # æ‰§è¡Œ Web UI å¯¼å‡º
        print(f"\n{'='*50}")
        print(f"å¼€å§‹ REAPER Web UI è¿œç¨‹å¯¼å‡º")
        print(f"èƒ¶å›Šç±»å‹: {capsule_type}")
        print(f"Web UI ç«¯å£: {webui_port}")
        print(f"æ¸²æŸ“é¢„è§ˆ: {render_preview}")
        print(f"å¯¼å‡ºç›®å½•: {export_dir}")
        print(f"æ¥æ”¶åˆ°çš„æ•°æ®: {data}")
        print(f"{'='*50}\n")

        result = quick_webui_export(
            project_name=project_name,
            theme_name=theme_name,
            render_preview=render_preview,
            webui_port=webui_port,
            capsule_type=capsule_type,
            export_dir=export_dir  # ä¼ é€’å¯¼å‡ºç›®å½•
        )

        print(f"\n{'='*50}")
        print(f"Web UI å¯¼å‡ºç»“æœ: {result}")
        print(f"{'='*50}\n")

        log_to_file(f"âœ… REAPER å¯¼å‡ºå®Œæˆ")
        log_to_file(f"è¿”å›çš„ capsule_name: {result.get('capsule_name')}")
        log_to_file(f"å¯¼å‡ºæˆåŠŸ: {result.get('success')}")

        if not result['success']:
            raise APIError(result.get('error', 'å¯¼å‡ºå¤±è´¥'))

        # è·å–å¯¼å‡ºçš„èƒ¶å›Šåç§°
        expected_capsule_name = result.get('capsule_name')
        print(f"ğŸ¯ æœŸæœ›çš„èƒ¶å›Šåç§°: {expected_capsule_name}")
        print(f"â³ ç­‰å¾…æ–‡ä»¶å®Œå…¨å†™å…¥...")

        # ä» PathManager è·å–å¯¼å‡ºç›®å½•
        from common import PathManager
        pm = PathManager.get_instance()
        output_dir = pm.export_dir
        print(f"ğŸ“ ä½¿ç”¨å¯¼å‡ºç›®å½•: {output_dir}")
        log_to_file(f"ğŸ“ ä½¿ç”¨å¯¼å‡ºç›®å½•: {output_dir}")

        # ç­‰å¾…æ–‡ä»¶å®Œå…¨å†™å…¥ï¼ˆæœ€å¤šç­‰å¾… 5 ç§’ï¼‰
        import time
        max_wait = 5  # æœ€å¤šç­‰å¾… 5 ç§’
        wait_interval = 0.5  # æ¯æ¬¡æ£€æŸ¥é—´éš” 0.5 ç§’
        waited = 0

        capsule_dir = output_dir / expected_capsule_name
        metadata_file = capsule_dir / 'metadata.json'

        while waited < max_wait:
            if metadata_file.exists():
                # æ–‡ä»¶å­˜åœ¨ï¼Œå†ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿å†™å…¥å®Œæˆ
                time.sleep(0.5)
                print(f"âœ… æ–‡ä»¶å·²åˆ›å»º: {metadata_file}")
                break
            print(f"   â³ ç­‰å¾…æ–‡ä»¶åˆ›å»º... ({waited}s)")
            time.sleep(wait_interval)
            waited += wait_interval

        if not metadata_file.exists():
            print(f"âš ï¸ è­¦å‘Š: ç­‰å¾… {max_wait}s åæ–‡ä»¶ä»æœªå­˜åœ¨ï¼Œç»§ç»­å°è¯•æ‰«æ")

        # å¯¼å‡ºæˆåŠŸå,è‡ªåŠ¨æ‰«æå¹¶å¯¼å…¥
        print("=" * 80)
        print("ğŸ”„ å¼€å§‹æ‰«æå’Œå¯¼å…¥æµç¨‹")
        print("=" * 80)

        # é‡æ–°åŠ è½½ capsule_scanner æ¨¡å—ä»¥è·å–æœ€æ–°çš„ OUTPUT_DIR
        import sys
        if 'capsule_scanner' in sys.modules:
            del sys.modules['capsule_scanner']
            print("â™»ï¸  é‡æ–°åŠ è½½ capsule_scanner æ¨¡å—")

        from capsule_scanner import import_specific_capsule

        # ç›´æ¥å¯¼å…¥æŒ‡å®šçš„èƒ¶å›Š
        print(f"\nğŸ¯ [æ­¥éª¤ 1] å¯¼å‡ºè¯·æ±‚çš„èƒ¶å›Šåç§°: {expected_capsule_name}")
        print(f"   ç”¨æˆ·é€‰æ‹©çš„èƒ¶å›Šç±»å‹: {capsule_type}")
        print(f"   å½“å‰ä½¿ç”¨çš„å¯¼å‡ºç›®å½•: {os.getenv('SYNESTH_CAPSULE_OUTPUT', 'æœªè®¾ç½®')}")

        # å°è¯•å¯¼å…¥æŒ‡å®šçš„èƒ¶å›Š
        imported_capsule = import_specific_capsule(expected_capsule_name)

        if not imported_capsule:
            print(f"\nâŒ [æ­¥éª¤ 2] å¯¼å…¥èƒ¶å›Šå¤±è´¥ï¼")
            print(f"   æœŸæœ›åç§°: {expected_capsule_name}")
            response = jsonify({
                'success': False,
                'error': f'å¯¼å‡ºæˆåŠŸä½†æ— æ³•å¯¼å…¥èƒ¶å›Š: {expected_capsule_name}'
            })
            response.headers.add('Access-Control-Allow-Origin', '*')
            return response

        print(f"\nâœ… [æ­¥éª¤ 2] æˆåŠŸå¯¼å…¥èƒ¶å›Š:")
        print(f"   - ID: {imported_capsule.get('id')}")
        print(f"   - name: {imported_capsule.get('name')}")
        print(f"   - capsule_type: {imported_capsule.get('capsule_type')}")
        print(f"   - preview_audio: {imported_capsule.get('preview_audio')}")

        capsule_id = imported_capsule['id']

        # æ‰“å°åŒ¹é…çš„æ•°æ®
        print(f"\nğŸ“¦ [æ­¥éª¤ 3] å‡†å¤‡æ›´æ–°çš„èƒ¶å›Šæ•°æ®:")
        print(f"   - id: {imported_capsule.get('id')}")
        print(f"   - name: {imported_capsule.get('name')}")
        print(f"   - capsule_type: {imported_capsule.get('capsule_type')}")
        print(f"   - preview_audio: {imported_capsule.get('preview_audio')}")
        print(f"   - file_path: {imported_capsule.get('file_path')}")

        try:
            # ä½¿ç”¨æ–°æ–¹æ³•ï¼šæ›´æ–°èƒ¶å›Šç±»å‹å¹¶ç«‹å³è¿”å›å®Œæ•´æ•°æ®
            print(f"\nğŸ”§ [æ­¥éª¤ 4] è°ƒç”¨ update_capsule_type_and_get()")
            print(f"   - capsule_id: {capsule_id}")
            print(f"   - æ–° capsule_type: {capsule_type}")

            db = get_database()
            updated_capsule = db.update_capsule_type_and_get(capsule_id, capsule_type)
            if updated_capsule:
                # ä½¿ç”¨æ›´æ–°åçš„æ•°æ®
                final_capsule = updated_capsule
                print(f"\nâœ… [æ­¥éª¤ 5] æ›´æ–°æˆåŠŸï¼Œæœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„æ•°æ®:")
                print(f"   - id: {updated_capsule.get('id')}")
                print(f"   - name: {updated_capsule.get('name')}")
                print(f"   - capsule_type: {updated_capsule.get('capsule_type')}")
                print(f"   - preview_audio: {updated_capsule.get('preview_audio')}")
                print(f"   - file_path: {updated_capsule.get('file_path')}")
                print("=" * 80)

                # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
                log_to_file("âœ… æœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„æ•°æ®:")
                log_to_file(f"  - id: {updated_capsule.get('id')}")
                log_to_file(f"  - name: {updated_capsule.get('name')}")
                log_to_file(f"  - capsule_type: {updated_capsule.get('capsule_type')}")
                log_to_file(f"  - preview_audio: {updated_capsule.get('preview_audio')}")
                log_to_file(f"  - file_path: {updated_capsule.get('file_path')}")
                log_to_file("=" * 80)
            else:
                print(f"\nâš ï¸ [æ­¥éª¤ 5] æ›´æ–°å¤±è´¥ï¼Œä½¿ç”¨åŸæ•°æ®")
                final_capsule = imported_capsule
        except Exception as e:
            print(f"\nâš ï¸ æ›´æ–°èƒ¶å›Šç±»å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            final_capsule = imported_capsule

        # è¿”å›å»ºè®®çš„æ£±é•œ
        lens_map = {
            'magic': 'texture',
            'impact': 'temperament',
            'atmosphere': 'materiality'
        }
        suggested_lens = lens_map.get(capsule_type, 'texture')

        response = jsonify({
            'success': True,
            'capsule_id': final_capsule['id'],
            'capsule_name': result.get('capsule_name'),
            'capsule_type': capsule_type,
            'suggested_lens': suggested_lens,
            'message': 'REAPER Web UI è¿œç¨‹å¯¼å‡ºæˆåŠŸ',
            'imported_count': 1,
            'auto_imported': [final_capsule]
        })
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type, Authorization')

        # è®°å½•æœ€ç»ˆå“åº”
        log_to_file("ğŸ“¤ è¿”å›ç»™å‰ç«¯çš„å®Œæ•´å“åº”:")
        log_to_file(f"  - success: True")
        log_to_file(f"  - capsule_id: {final_capsule['id']}")
        log_to_file(f"  - capsule_name: {result.get('capsule_name')}")
        log_to_file(f"  - capsule_type: {capsule_type}")
        log_to_file(f"  - auto_imported æ•°é‡: 1")
        log_to_file(f"  - auto_imported[0].name: {final_capsule.get('name')}")
        log_to_file(f"  - auto_imported[0].id: {final_capsule.get('id')}")
        log_to_file("=" * 80)

        return response

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"Web UI å¯¼å‡ºå¤±è´¥: {e}", 500)


# ============================================
# OSC è¿œç¨‹è§¦å‘å¯¼å‡º (å¤‡ç”¨æ–¹æ¡ˆ)
# ============================================

@app.route('/api/capsules/osc-export', methods=['POST'])
def osc_export_api():
    """
    OSC è¿œç¨‹è§¦å‘å¯¼å‡º: é€šè¿‡ OSC åè®®è¿œç¨‹æ§åˆ¶ REAPER æ‰§è¡Œå¯¼å‡º

    è¯·æ±‚ä½“:
        {
            "project_name": "é¡¹ç›®å",
            "theme_name": "ä¸»é¢˜å",
            "render_preview": true,
            "osc_port": 9000  # å¯é€‰,é»˜è®¤ 9000
        }

    å“åº”:
        {
            "success": true,
            "capsule_name": "é¡¹ç›®å_ä¸»é¢˜å",
            "message": "å¯¼å‡ºæˆåŠŸ"
        }
    """
    try:
        from exporters.reaper_osc_export import quick_osc_export

        data = request.get_json()

        project_name = data.get('project_name', '').strip()
        theme_name = data.get('theme_name', '').strip()
        render_preview = data.get('render_preview', True)
        osc_port = data.get('osc_port', 9000)

        if not project_name:
            raise APIError("é¡¹ç›®åä¸èƒ½ä¸ºç©º")

        if not theme_name:
            raise APIError("ä¸»é¢˜åä¸èƒ½ä¸ºç©º")

        # æ‰§è¡Œ OSC å¯¼å‡º
        print(f"\n{'='*50}")
        print(f"å¼€å§‹ OSC è¿œç¨‹å¯¼å‡º: {project_name}_{theme_name}")
        print(f"OSC ç«¯å£: {osc_port}")
        print(f"{'='*50}\n")

        result = quick_osc_export(
            project_name=project_name,
            theme_name=theme_name,
            render_preview=render_preview,
            osc_port=osc_port
        )

        print(f"\n{'='*50}")
        print(f"OSC å¯¼å‡ºç»“æœ: {result}")
        print(f"{'='*50}\n")

        if not result['success']:
            raise APIError(result.get('error', 'å¯¼å‡ºå¤±è´¥'))

        # å¯¼å‡ºæˆåŠŸå,è‡ªåŠ¨æ‰«æå¹¶å¯¼å…¥
        from capsule_scanner import scan_and_import_all
        imported = scan_and_import_all()

        return jsonify({
            'success': True,
            'capsule_name': result.get('capsule_name'),
            'message': 'OSC è¿œç¨‹å¯¼å‡ºæˆåŠŸ',
            'imported_count': len(imported),
            'auto_imported': imported
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"OSC å¯¼å‡ºå¤±è´¥: {e}", 500)


# ============================================
# æ£€æŸ¥ REAPER è§¦å‘çŠ¶æ€
# ============================================

@app.route('/api/capsules/check-reaper-trigger', methods=['GET'])
def check_reaper_trigger():
    """
    æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ª REAPER çš„è§¦å‘ä¿¡å·

    å½“ç”¨æˆ·åœ¨ REAPER ä¸­æŒ‰å¿«æ·é”®æ—¶,ä¼šç”Ÿæˆè§¦å‘æ–‡ä»¶

    å“åº”:
        {
            "success": true,
            "has_trigger": true,
            "project_name": "é¡¹ç›®å",
            "item_count": 3
        }
    """
    try:
        from exporters.reaper_trigger_export import read_reaper_trigger

        trigger_config = read_reaper_trigger()

        if trigger_config:
            return jsonify({
                'success': True,
                'has_trigger': True,
                'project_name': trigger_config.get('project_name'),
                'item_count': trigger_config.get('item_count'),
                'timestamp': trigger_config.get('timestamp')
            })
        else:
            return jsonify({
                'success': True,
                'has_trigger': False
            })

    except Exception as e:
        raise APIError(f"æ£€æŸ¥è§¦å‘çŠ¶æ€å¤±è´¥: {e}", 500)


# ============================================
# æ‰«æå¹¶å¯¼å…¥æ–°èƒ¶å›Š
# ============================================

@app.route('/api/capsules/scan-and-import', methods=['POST'])
def scan_and_import_capsules():
    """
    æ‰«æ output ç›®å½•å¹¶å¯¼å…¥æ–°å‘ç°çš„èƒ¶å›Š

    è¯·æ±‚ä½“:
        {}

    å“åº”:
        {
            "success": true,
            "imported": [
                {"id": 1, "name": "é¡¹ç›®_ä¸»é¢˜"},
                {"id": 2, "name": "é¡¹ç›®2_ä¸»é¢˜2"}
            ],
            "count": 2
        }
    """
    try:
        from capsule_scanner import scan_and_import_all

        imported = scan_and_import_all()

        return jsonify({
            'success': True,
            'imported': imported,
            'count': len(imported)
        })

    except Exception as e:
        raise APIError(f"æ‰«æå¤±è´¥: {e}", 500)


# ============================================
# èƒ¶å›Šç±»å‹ç®¡ç†
# ============================================

@app.route('/api/capsule-types', methods=['GET'])
def get_capsule_types():
    """è·å–æ‰€æœ‰èƒ¶å›Šç±»å‹"""
    try:
        db = get_database()
        types = db.get_all_capsule_types()

        return jsonify({
            'success': True,
            'types': types
        })

    except Exception as e:
        raise APIError(f"è·å–èƒ¶å›Šç±»å‹å¤±è´¥: {e}", 500)


@app.route('/api/capsule-types/<type_id>', methods=['GET'])
def get_capsule_type(type_id):
    """è·å–å•ä¸ªèƒ¶å›Šç±»å‹"""
    try:
        db = get_database()
        capsule_type = db.get_capsule_type(type_id)

        if not capsule_type:
            raise APIError(f"èƒ¶å›Šç±»å‹ä¸å­˜åœ¨: {type_id}", 404)

        return jsonify({
            'success': True,
            'type': capsule_type
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å–èƒ¶å›Šç±»å‹å¤±è´¥: {e}", 500)


@app.route('/api/capsule-types', methods=['POST'])
def create_capsule_type():
    """åˆ›å»ºæ–°çš„èƒ¶å›Šç±»å‹"""
    try:
        data = request.get_json()

        # éªŒè¯å¿…å¡«å­—æ®µ
        required_fields = ['id', 'name', 'name_cn', 'color', 'gradient']
        for field in required_fields:
            if field not in data:
                raise APIError(f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}", 400)

        # éªŒè¯IDæ ¼å¼ï¼ˆåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰
        import re
        if not re.match(r'^[a-zA-Z0-9_]+$', data['id']):
            raise APIError("IDåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿", 400)

        db = get_database()
        success = db.create_capsule_type(data)

        if success:
            return jsonify({
                'success': True,
                'message': f"æˆåŠŸåˆ›å»ºèƒ¶å›Šç±»å‹: {data['name_cn']}"
            })
        else:
            raise APIError("åˆ›å»ºå¤±è´¥ï¼Œå¯èƒ½æ˜¯IDå·²å­˜åœ¨", 400)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"åˆ›å»ºèƒ¶å›Šç±»å‹å¤±è´¥: {e}", 500)


@app.route('/api/capsule-types/<type_id>', methods=['PUT'])
def update_capsule_type(type_id):
    """æ›´æ–°èƒ¶å›Šç±»å‹"""
    try:
        data = request.get_json()

        db = get_database()
        # æ£€æŸ¥ç±»å‹æ˜¯å¦å­˜åœ¨
        existing = db.get_capsule_type(type_id)
        if not existing:
            raise APIError(f"èƒ¶å›Šç±»å‹ä¸å­˜åœ¨: {type_id}", 404)

        success = db.update_capsule_type(type_id, data)

        if success:
            return jsonify({
                'success': True,
                'message': f"æˆåŠŸæ›´æ–°èƒ¶å›Šç±»å‹: {type_id}"
            })
        else:
            raise APIError("æ›´æ–°å¤±è´¥ï¼Œæ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ", 400)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æ›´æ–°èƒ¶å›Šç±»å‹å¤±è´¥: {e}", 500)


@app.route('/api/capsule-types/<type_id>', methods=['DELETE'])
def delete_capsule_type(type_id):
    """åˆ é™¤èƒ¶å›Šç±»å‹"""
    try:
        db = get_database()

        # æ£€æŸ¥ç±»å‹æ˜¯å¦å­˜åœ¨
        existing = db.get_capsule_type(type_id)
        if not existing:
            raise APIError(f"èƒ¶å›Šç±»å‹ä¸å­˜åœ¨: {type_id}", 404)

        # æ£€æŸ¥æ˜¯å¦æœ‰èƒ¶å›Šä½¿ç”¨æ­¤ç±»å‹
        capsules = db.get_all_capsules()
        in_use = any(c['capsule_type'] == type_id for c in capsules)

        if in_use:
            raise APIError(f"æ— æ³•åˆ é™¤ï¼šä»æœ‰èƒ¶å›Šæ­£åœ¨ä½¿ç”¨æ­¤ç±»å‹", 400)

        success = db.delete_capsule_type(type_id)

        if success:
            return jsonify({
                'success': True,
                'message': f"æˆåŠŸåˆ é™¤èƒ¶å›Šç±»å‹: {type_id}"
            })
        else:
            raise APIError("åˆ é™¤å¤±è´¥", 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"åˆ é™¤èƒ¶å›Šç±»å‹å¤±è´¥: {e}", 500)


# ============================================
# äº‘ç«¯åŒæ­¥ API ç«¯ç‚¹
# ============================================

@app.route('/api/sync/status', methods=['GET'])
def get_sync_status_endpoint():
    """
    è·å–åŒæ­¥çŠ¶æ€æ¦‚è§ˆ

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "synced_count": 10,
                "pending_count": 3,
                "conflict_count": 0,
                "last_sync_at": "2026-01-10T10:00:00Z"
            }
        }
    """
    try:
        sync_service = get_sync_service()
        status = sync_service.get_sync_status()

        return jsonify({
            'success': True,
            'data': status
        })

    except Exception as e:
        raise APIError(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}", 500)


@app.route('/api/sync/pending', methods=['GET'])
def get_pending_records():
    """
    è·å–å¾…åŒæ­¥çš„è®°å½•

    Query Parameters:
        - table: è¡¨åï¼ˆå¯é€‰ï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "records": [...]
            }
        }
    """
    try:
        table_name = request.args.get('table')

        sync_service = get_sync_service()
        records = sync_service.get_pending_records(table_name)

        return jsonify({
            'success': True,
            'data': {
                'records': records,
                'count': len(records)
            }
        })

    except Exception as e:
        raise APIError(f"è·å–å¾…åŒæ­¥è®°å½•å¤±è´¥: {e}", 500)


@app.route('/api/sync/mark-pending', methods=['POST'])
@token_required
def mark_record_for_sync(current_user):
    """
    æ ‡è®°è®°å½•ä¸ºå¾…åŒæ­¥

    è¯·æ±‚ä½“:
        {
            "table": "capsules",
            "record_id": 123,
            "operation": "update"
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "å·²æ ‡è®°ä¸ºå¾…åŒæ­¥"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        # å…¼å®¹ä¸¤ç§å‚æ•°æ ¼å¼
        table_name = data.get('table') or data.get('table_name')
        record_id = data.get('record_id') or data.get('record_id')
        operation = data.get('operation', 'update')

        if not all([table_name, record_id]):
            raise APIError('ç¼ºå°‘å¿…è¦å‚æ•°: table, record_id', 400)

        sync_service = get_sync_service()
        success = sync_service.mark_for_sync(table_name, record_id, operation)

        if success:
            return jsonify({
                'success': True,
                'message': 'å·²æ ‡è®°ä¸ºå¾…åŒæ­¥'
            })
        else:
            raise APIError('æ ‡è®°å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æ ‡è®°å¾…åŒæ­¥å¤±è´¥: {e}", 500)


@app.route('/api/sync/upload', methods=['POST'])
@token_required
def upload_to_cloud(current_user):
    """
    ä¸Šä¼ æ•°æ®åˆ°äº‘ç«¯

    è¯·æ±‚ä½“:
        {
            "table": "capsules",
            "records": [...]
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "uploaded": 5,
                "failed": 0
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        table_name = data.get('table')
        records = data.get('records', [])

        if not table_name:
            raise APIError('ç¼ºå°‘è¡¨å', 400)

        # è°ƒè¯•æ—¥å¿—
        logger.info(f"\n{'='*60}")
        logger.info(f"[SYNC] å¼€å§‹ä¸Šä¼ åˆ°äº‘ç«¯")
        logger.info(f"[SYNC] è¡¨å: {table_name}")
        logger.info(f"[SYNC] è®°å½•æ•°: {len(records)}")
        logger.info(f"[SYNC] å®Œæ•´è¯·æ±‚ä½“: {data}")
        if records:
            logger.info(f"[SYNC] ç¬¬ä¸€æ¡è®°å½•: {records[0]}")
        logger.info(f"{'='*60}\n")

        # çœŸå®çš„äº‘ç«¯ä¸Šä¼ é€»è¾‘
        try:
            from supabase_client import get_supabase_client

            supabase = get_supabase_client()
            if not supabase:
                raise Exception("Supabase å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

            # è·å–ç”¨æˆ· IDï¼ˆä¼˜å…ˆä½¿ç”¨ supabase_user_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœ¬åœ° IDï¼‰
            user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

            uploaded = 0
            failed = 0
            cloud_id_mapping = {}  # æœ¬åœ° ID -> äº‘ç«¯ ID æ˜ å°„

            # æ ¹æ®ä¸åŒçš„è¡¨åå¤„ç†
            if table_name == 'capsules':
                # è·å–æœ¬åœ°æ•°æ®åº“è¿æ¥
                db = get_database()
                db.connect()
                cursor = db.conn.cursor()

                try:
                    # ä¸Šä¼ èƒ¶å›Šæ•°æ®
                    for idx, pending_record in enumerate(records, 1):
                        logger.info(f"\n[SYNC] å¤„ç†ç¬¬ {idx}/{len(records)} æ¡è®°å½•...")
                        try:
                            # ä» pending_record ä¸­è·å–å®é™…çš„ record_id
                            record_id = pending_record.get('record_id')
                            logger.info(f"[SYNC]   record_id: {record_id}")

                            # ä»æ•°æ®åº“è·å–å®Œæ•´çš„èƒ¶å›Šæ•°æ®
                            cursor.execute("SELECT * FROM capsules WHERE id = ?", (record_id,))
                            row = cursor.fetchone()

                            if not row:
                                logger.warning(f"[SYNC]   âœ— è­¦å‘Š: èƒ¶å›Š ID {record_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                                failed += 1
                                continue

                            # å°†è¡Œæ•°æ®è½¬æ¢ä¸ºå­—å…¸
                            columns = [desc[0] for desc in cursor.description]
                            capsule_data = dict(zip(columns, row))

                            # è·å–æŠ€æœ¯å…ƒæ•°æ®
                            cursor.execute("""SELECT bpm, duration, sample_rate, plugin_count, plugin_list,
                                                   has_sends, has_folder_bus, tracks_included
                                            FROM capsule_metadata WHERE capsule_id = ?""", (record_id,))
                            metadata_row = cursor.fetchone()
                            if metadata_row:
                                capsule_data['bpm'] = metadata_row[0]
                                capsule_data['duration'] = metadata_row[1]
                                capsule_data['sample_rate'] = metadata_row[2]
                                capsule_data['plugin_count'] = metadata_row[3]
                                capsule_data['plugin_list'] = metadata_row[4]
                                capsule_data['has_sends'] = metadata_row[5]
                                capsule_data['has_folder_bus'] = metadata_row[6]
                                capsule_data['tracks_included'] = metadata_row[7]

                            logger.info(f"[SYNC]   âœ“ èƒ¶å›Šåç§°: {capsule_data.get('name')}")

                            # ä¸Šä¼ åˆ°äº‘ç«¯
                            logger.info(f"[SYNC]   â†’ æ­£åœ¨ä¸Šä¼ åˆ° Supabase...")
                            result = supabase.upload_capsule(user_id, capsule_data)

                            if result:
                                uploaded += 1
                                cloud_id = result.get('id')
                                cloud_id_mapping[record_id] = cloud_id
                                logger.info(f"[SYNC]   âœ“ ä¸Šä¼ æˆåŠŸ!")
                                logger.info(f"[SYNC]     - æœ¬åœ°ID: {record_id}")
                                logger.info(f"[SYNC]     - äº‘ç«¯ID: {cloud_id}")
                                logger.info(f"[SYNC]     - ç‰ˆæœ¬: {result.get('version')}")

                                # ğŸ¯ ä¸Šä¼  Audio æ–‡ä»¶å¤¹ï¼ˆREAPER é¡¹ç›®æ‰€éœ€ï¼‰
                                import os
                                capsule_dir = capsule_data.get('file_path', '')
                                if capsule_dir:
                                    from pathlib import Path
                                    import glob

                                    # æœç´¢å¤šä¸ªå¯èƒ½çš„å¯¼å‡ºç›®å½•
                                    possible_dirs = []
                                    base_dir = Path(__file__).parent

                                    # 1. output ç›®å½•ï¼ˆé»˜è®¤ï¼‰
                                    possible_dirs.append(base_dir / 'output' / capsule_dir)

                                    # 2. ä»ç¯å¢ƒå˜é‡è¯»å–å¯¼å‡ºç›®å½•ï¼ˆå‰ç«¯è®¾ç½®ï¼‰
                                    export_dir_env = os.getenv('SYNESTH_CAPSULE_OUTPUT')
                                    if export_dir_env:
                                        possible_dirs.append(Path(export_dir_env) / capsule_dir)
                                        logger.info(f"[SYNC] ä½¿ç”¨ç¯å¢ƒå˜é‡å¯¼å‡ºç›®å½•: {export_dir_env}")

                                    # 3. ä» PathManager è·å–å¯¼å‡ºç›®å½•
                                    from common import PathManager
                                    pm = PathManager.get_instance()
                                    export_dir = pm.export_dir
                                    possible_dirs.append(Path(export_dir) / capsule_dir)
                                    logger.info(f"[SYNC] ä½¿ç”¨ PathManager å¯¼å‡ºç›®å½•: {export_dir}")

                                    # 4. ç›´æ¥åœ¨ base_dir ä¸‹æœç´¢
                                    possible_dirs.append(base_dir / capsule_dir)

                                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå­˜åœ¨çš„ç›®å½•
                                    full_capsule_dir = None
                                    logger.info(f"[SYNC] ğŸ” æœç´¢èƒ¶å›Šç›®å½•: {capsule_dir}")
                                    for idx, dir_path in enumerate(possible_dirs, 1):
                                        logger.info(f"[SYNC]   [{idx}] æ£€æŸ¥: {dir_path} - {'âœ“ å­˜åœ¨' if dir_path.exists() else 'âœ— ä¸å­˜åœ¨'}")
                                        if dir_path.exists():
                                            full_capsule_dir = dir_path
                                            logger.info(f"[SYNC] âœ“ æ‰¾åˆ°èƒ¶å›Šç›®å½•: {full_capsule_dir}")
                                            break

                                    if full_capsule_dir:
                                        # ğŸµ ä¸Šä¼ é¢„è§ˆéŸ³é¢‘æ–‡ä»¶
                                        preview_audio = capsule_data.get('preview_audio')
                                        if preview_audio:
                                            preview_path = full_capsule_dir / preview_audio
                                            if preview_path.exists():
                                                logger.info(f"[SYNC] â†’ ä¸Šä¼ é¢„è§ˆéŸ³é¢‘: {preview_audio}")
                                                preview_result = supabase.upload_file(
                                                    user_id=user_id,
                                                    capsule_folder_name=capsule_dir,  # ä½¿ç”¨æ–‡ä»¶å¤¹å
                                                    file_type='preview',
                                                    file_path=str(preview_path)
                                                )
                                                if preview_result:
                                                    logger.info(f"[SYNC]   âœ“ é¢„è§ˆéŸ³é¢‘ä¸Šä¼ æˆåŠŸ")
                                                    logger.info(f"[SYNC]     - å¤§å°: {preview_result.get('size', 0):,} bytes")
                                                    logger.info(f"[SYNC]     - è·¯å¾„: {preview_result.get('storage_path', 'N/A')}")
                                                else:
                                                    logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘ä¸Šä¼ å¤±è´¥")
                                            else:
                                                logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {preview_path}")

                                        # ğŸ“„ ä¸Šä¼  RPP é¡¹ç›®æ–‡ä»¶
                                        rpp_file = capsule_data.get('rpp_file')
                                        if rpp_file:
                                            rpp_path = full_capsule_dir / rpp_file
                                            if rpp_path.exists():
                                                logger.info(f"[SYNC] â†’ ä¸Šä¼  RPP æ–‡ä»¶: {rpp_file}")
                                                rpp_result = supabase.upload_file(
                                                    user_id=user_id,
                                                    capsule_folder_name=capsule_dir,  # ä½¿ç”¨æ–‡ä»¶å¤¹å
                                                    file_type='rpp',
                                                    file_path=str(rpp_path)
                                                )
                                                if rpp_result:
                                                    logger.info(f"[SYNC]   âœ“ RPP æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                                                    logger.info(f"[SYNC]     - å¤§å°: {rpp_result.get('size', 0):,} bytes")
                                                    logger.info(f"[SYNC]     - è·¯å¾„: {rpp_result.get('storage_path', 'N/A')}")
                                                else:
                                                    logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
                                            else:
                                                logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸å­˜åœ¨: {rpp_path}")

                                        # ğŸ§ ä¸Šä¼  Audio æ–‡ä»¶å¤¹ï¼ˆREAPER é¡¹ç›®æ‰€éœ€ï¼‰
                                        audio_folder = full_capsule_dir / "Audio"
                                        if audio_folder.exists():
                                            logger.info(f"[SYNC] â†’ ä¸Šä¼  Audio æ–‡ä»¶å¤¹...")
                                            audio_result = supabase.upload_file(
                                                user_id=user_id,
                                                capsule_folder_name=capsule_dir,  # ä½¿ç”¨æ–‡ä»¶å¤¹å
                                                file_type='audio_folder',
                                                file_path=str(audio_folder)
                                            )
                                            if audio_result and audio_result.get('success', False):
                                                logger.info(f"[SYNC]   âœ“ Audio æ–‡ä»¶å¤¹ä¸Šä¼ æˆåŠŸ")
                                                logger.info(f"[SYNC]     - æ–‡ä»¶æ•°: {audio_result.get('files_uploaded', 0)}")
                                                logger.info(f"[SYNC]     - æ€»å¤§å°: {audio_result.get('total_size', 0):,} bytes ({audio_result.get('total_size', 0) / 1024 / 1024:.2f} MB)")
                                                if audio_result.get('errors'):
                                                    logger.warning(f"[SYNC]     - å¤±è´¥: {len(audio_result.get('errors', []))} ä¸ªæ–‡ä»¶")
                                            else:
                                                logger.warning(f"[SYNC]   âš  Audio æ–‡ä»¶å¤¹ä¸Šä¼ å¤±è´¥")
                                        else:
                                            logger.info(f"[SYNC]   â„¹ æ—  Audio æ–‡ä»¶å¤¹ï¼Œè·³è¿‡")
                                    else:
                                        logger.warning(f"[SYNC] âš  æ— æ³•æ‰¾åˆ°èƒ¶å›Šç›®å½•: {capsule_dir}")

                                # æ›´æ–°æœ¬åœ°æ•°æ®åº“çš„äº‘åŒæ­¥çŠ¶æ€
                                cursor.execute("""
                                    UPDATE capsules
                                    SET cloud_status = 'synced',
                                        cloud_id = ?,
                                        cloud_version = ?,
                                        last_synced_at = CURRENT_TIMESTAMP
                                    WHERE id = ?
                                """, (cloud_id, result.get('version', 1), record_id))
                                db.conn.commit()
                                logger.info(f"[SYNC]   âœ“ å·²æ›´æ–°æœ¬åœ°åŒæ­¥çŠ¶æ€")
                            else:
                                failed += 1
                                logger.error(f"[SYNC]   âœ— ä¸Šä¼ å¤±è´¥: result is None")
                        except Exception as e:
                            failed += 1
                            logger.error(f"[SYNC]   âœ— å¼‚å¸¸: {e}")
                            import traceback
                            logger.error(traceback.format_exc())

                    # ä¸Šä¼ èƒ¶å›Šçš„æ ‡ç­¾å’Œåæ ‡ï¼ˆä½¿ç”¨å·²æœ‰çš„ db å’Œ cursorï¼‰
                    if cloud_id_mapping:
                        logger.info(f"[SYNC] ğŸ“ å‡†å¤‡ä¸Šä¼ æ ‡ç­¾ï¼Œcloud_id_mapping: {cloud_id_mapping}")
                        for local_id, cloud_id in cloud_id_mapping.items():
                            # ä¸Šä¼ æ ‡ç­¾
                            cursor.execute("SELECT * FROM capsule_tags WHERE capsule_id = ?", (local_id,))
                            tags = []
                            for row in cursor.fetchall():
                                tags.append({
                                    'lens': row[2],         # ä½¿ç”¨ç»Ÿä¸€çš„ lens å‘½å
                                    'word_id': row[3],      # word_id
                                    'word_cn': row[4],      # word_cn
                                    'word_en': row[5],      # word_en
                                    'x': row[6],            # x
                                    'y': row[7],            # y
                                })
                            logger.info(f"[SYNC] ğŸ“ æœ¬åœ°èƒ¶å›Š {local_id} æœ‰ {len(tags)} ä¸ªæ ‡ç­¾")
                            if tags:
                                logger.info(f"[SYNC] â†’ ä¸Šä¼ æ ‡ç­¾åˆ°äº‘ç«¯ (capsule_id={cloud_id})...")
                                supabase.upload_tags(user_id, cloud_id, tags)
                            else:
                                logger.warning(f"[SYNC] âš  æœ¬åœ°èƒ¶å›Š {local_id} æ²¡æœ‰æ ‡ç­¾")

                            # ä¸Šä¼ åæ ‡
                            cursor.execute("SELECT * FROM capsule_coordinates WHERE capsule_id = ?", (local_id,))
                            coords = []
                            for row in cursor.fetchall():
                                coords.append({
                                    'lens': row[2],
                                    'dimension': row[3],
                                    'value': row[4],
                                })
                            if coords:
                                supabase.upload_coordinates(user_id, cloud_id, coords)
                finally:
                    # ç¡®ä¿å…³é—­æ•°æ®åº“è¿æ¥
                    db.close()

            elif table_name == 'capsule_tags':
                # æ ‡ç­¾ä¼šéšç€èƒ¶å›Šä¸€èµ·ä¸Šä¼ 
                uploaded = len(records)
            elif table_name == 'capsule_coordinates':
                # åæ ‡ä¼šéšç€èƒ¶å›Šä¸€èµ·ä¸Šä¼ 
                uploaded = len(records)
            else:
                raise Exception(f"ä¸æ”¯æŒçš„è¡¨å: {table_name}")

            # æ ‡è®°ä¸ºå·²åŒæ­¥ï¼ˆåªæ ‡è®°æˆåŠŸä¸Šä¼ çš„è®°å½•ï¼‰
            sync_service = get_sync_service()
            synced_count = 0

            for pending_record in records:
                record_id = pending_record.get('record_id')
                if record_id and record_id in cloud_id_mapping:
                    # åªæœ‰æˆåŠŸä¸Šä¼ åˆ°äº‘ç«¯çš„è®°å½•æ‰æ ‡è®°ä¸ºå·²åŒæ­¥
                    sync_service.mark_as_synced(table_name, record_id, 1)
                    synced_count += 1
                    logger.info(f"[SYNC] æ ‡è®°ä¸ºå·²åŒæ­¥: {table_name} ID {record_id}")

            logger.info(f"[SYNC] åŒæ­¥å®Œæˆ: æˆåŠŸ {uploaded}, å¤±è´¥ {failed}, æ ‡è®° {synced_count}")

            return jsonify({
                'success': True,
                'data': {
                    'uploaded': uploaded,
                    'failed': failed
                }
            })

        except ImportError:
            raise Exception("Supabase SDK æœªå®‰è£…")
        except Exception as e:
            raise Exception(f"äº‘ç«¯ä¸Šä¼ å¤±è´¥: {str(e)}")

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"ä¸Šä¼ åˆ°äº‘ç«¯å¤±è´¥: {e}", 500)


@app.route('/api/sync/download', methods=['GET'])
@token_required
def download_from_cloud(current_user):
    """
    ä»äº‘ç«¯ä¸‹è½½æ•°æ®

    Query Parameters:
        - table: è¡¨å
        - since: ISO 8601 æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "records": [...],
                "deleted_ids": [...]
            }
        }
    """
    try:
        table_name = request.args.get('table')
        since = request.args.get('since')

        if not table_name:
            raise APIError('ç¼ºå°‘è¡¨å', 400)

        # çœŸå®çš„äº‘ç«¯ä¸‹è½½é€»è¾‘
        try:
            from supabase_client import get_supabase_client

            supabase = get_supabase_client()
            if not supabase:
                raise Exception("Supabase å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

            # è·å–ç”¨æˆ· IDï¼ˆä¼˜å…ˆä½¿ç”¨ supabase_user_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœ¬åœ° IDï¼‰
            user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

            # æ ¹æ® table_name ä¸‹è½½å¯¹åº”çš„æ•°æ®
            if table_name == 'capsules':
                records = supabase.download_capsules(user_id)

                # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
                if records:
                    db = get_database()
                    db.connect()
                    try:
                        for record in records:
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            cursor = db.conn.cursor()
                            cursor.execute("SELECT id FROM capsules WHERE cloud_id = ?", (record.get('id'),))
                            existing = cursor.fetchone()

                            # å‡†å¤‡æœ¬åœ°æ•°æ®
                            # äº‘ç«¯çš„ name å­—æ®µå°±æ˜¯æ–‡ä»¶å¤¹åï¼ˆå¦‚ template_ianzhao_20260111_215759ï¼‰
                            # æœ¬åœ°çš„ file_path å­—æ®µå­˜å‚¨æ–‡ä»¶å¤¹å
                            capsule_folder_name = record.get('name', '')

                            local_data = {
                                'uuid': record.get('id'),
                                'name': record.get('name'),
                                'file_path': capsule_folder_name,  # ç›´æ¥ä½¿ç”¨ name å­—æ®µä½œä¸ºæ–‡ä»¶å¤¹è·¯å¾„
                                'preview_audio': record.get('metadata', {}).get('preview_audio'),
                                'rpp_file': record.get('metadata', {}).get('rpp_file'),
                                'capsule_type': record.get('metadata', {}).get('capsule_type', 'magic'),
                                'cloud_status': 'synced',
                                'cloud_id': record.get('id'),
                                'cloud_version': record.get('version', 1),
                            }

                            if existing:
                                # æ›´æ–°ç°æœ‰è®°å½•
                                cursor.execute("""
                                    UPDATE capsules
                                    SET name = ?, file_path = ?, preview_audio = ?, rpp_file = ?,
                                        capsule_type = ?, cloud_status = ?, cloud_id = ?, cloud_version = ?,
                                        last_synced_at = CURRENT_TIMESTAMP
                                    WHERE id = ?
                                """, (
                                    local_data['name'], local_data['file_path'], local_data['preview_audio'],
                                    local_data['rpp_file'], local_data['capsule_type'], local_data['cloud_status'],
                                    local_data['cloud_id'], local_data['cloud_version'], existing[0]
                                ))
                            else:
                                # æ’å…¥æ–°è®°å½•
                                cursor.execute("""
                                    INSERT INTO capsules (uuid, name, file_path, preview_audio, rpp_file,
                                                         capsule_type, cloud_status, cloud_id, cloud_version)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                                """, (
                                    local_data['uuid'], local_data['name'], local_data['file_path'],
                                    local_data['preview_audio'], local_data['rpp_file'], local_data['capsule_type'],
                                    local_data['cloud_status'], local_data['cloud_id'], local_data['cloud_version']
                                ))

                                # è·å–æ–°æ’å…¥çš„èƒ¶å›ŠID
                                capsule_id = cursor.lastrowid

                                # ä»äº‘ç«¯ metadata æ¢å¤æŠ€æœ¯å…ƒæ•°æ®
                                metadata = record.get('metadata', {})
                                if metadata.get('bpm') or metadata.get('plugin_count'):
                                    cursor.execute("""
                                        INSERT INTO capsule_metadata
                                        (capsule_id, bpm, duration, sample_rate, plugin_count, plugin_list,
                                         has_sends, has_folder_bus, tracks_included)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        capsule_id,
                                        metadata.get('bpm'),
                                        metadata.get('duration'),
                                        metadata.get('sample_rate'),
                                        metadata.get('plugin_count'),
                                        metadata.get('plugin_list'),
                                        metadata.get('has_sends'),
                                        metadata.get('has_folder_bus'),
                                        metadata.get('tracks_included')
                                    ))

                                # ä»äº‘ç«¯è·å–å¹¶æ¢å¤æ ‡ç­¾
                                cloud_tags = supabase.download_capsule_tags(record.get('id'))
                                if cloud_tags:
                                    for tag in cloud_tags:
                                        cursor.execute("""
                                            INSERT INTO capsule_tags
                                            (capsule_id, lens, word_id, word_cn, word_en, x, y)
                                            VALUES (?, ?, ?, ?, ?, ?, ?)
                                        """, (
                                            capsule_id,
                                            tag.get('lens') or tag.get('lens_id'),
                                            tag.get('word_id'),
                                            tag.get('word_cn'),
                                            tag.get('word_en'),
                                            tag.get('x'),
                                            tag.get('y')
                                        ))

                                # ä»äº‘ç«¯è·å–å¹¶æ¢å¤åæ ‡
                                try:
                                    # è¿™é‡Œç›´æ¥æŸ¥è¯¢ cloud_capsule_coordinates è¡¨
                                    cloud_coords_res = supabase.client.table('cloud_capsule_coordinates').select('*').eq('capsule_id', record.get('id')).execute()
                                    if cloud_coords_res.data:
                                        for coord in cloud_coords_res.data:
                                            cursor.execute("""
                                                INSERT INTO capsule_coordinates
                                                (capsule_id, lens, dimension, value)
                                                VALUES (?, ?, ?, ?)
                                            """, (
                                                capsule_id,
                                                coord.get('lens') or coord.get('lens_id'),
                                                coord.get('dimension'),
                                                coord.get('value')
                                            ))
                                except Exception as e:
                                    logger.warning(f"æ¢å¤åæ ‡å¤±è´¥ (èƒ¶å›Š {capsule_id}): {e}")

                                # åˆ›å»ºåŒæ­¥çŠ¶æ€è®°å½•
                                cursor.execute("""
                                    INSERT OR REPLACE INTO sync_status
                                    (table_name, record_id, sync_state, local_version, cloud_version, created_at, updated_at)
                                    VALUES ('capsules', ?, 'synced', ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                                """, (capsule_id, record.get('version', 1), record.get('version', 1)))

                                # ğŸ“¥ ä¸‹è½½æ–‡ä»¶ï¼ˆåªå¯¹æ–°ä¸‹è½½çš„èƒ¶å›Šï¼‰
                                try:
                                    from pathlib import Path
                                    import os

                                    # ç¡®å®šå¯¼å‡ºç›®å½• - ä» PathManager è·å–
                                    from common import PathManager
                                    pm = PathManager.get_instance()
                                    export_dir = pm.export_dir
                                    capsule_dir = Path(export_dir) / local_data['file_path']
                                    capsule_dir.mkdir(parents=True, exist_ok=True)

                                    logger.info(f"[SYNC] ğŸ“¥ å¼€å§‹ä¸‹è½½èƒ¶å›Šæ–‡ä»¶: {local_data['name']}")

                                    # é‡è¦ï¼šä½¿ç”¨äº‘ç«¯è®°å½•ä¸­çš„åŸä½œè€… user_id (Shared Mode ä¸‹ user_id å¯èƒ½ä¸æ˜¯å½“å‰ç™»å½•ç”¨æˆ·)
                                    owner_id = record.get('user_id')
                                    if not owner_id:
                                        owner_id = user_id
                                        
                                    # 1. ä¸‹è½½é¢„è§ˆéŸ³é¢‘
                                    if local_data['preview_audio']:
                                        preview_path = capsule_dir / local_data['preview_audio']
                                        logger.info(f"[SYNC]   â†’ ä¸‹è½½é¢„è§ˆéŸ³é¢‘: {local_data['preview_audio']}")
                                        logger.info(f"[SYNC]     æ–‡ä»¶å¤¹: {local_data['file_path']}, ä½œè€…: {owner_id}, è·¯å¾„: {owner_id}/{local_data['file_path']}/preview")
                                        if supabase.download_file(owner_id, local_data['file_path'], 'preview', str(preview_path)):
                                            logger.info(f"[SYNC]   âœ“ é¢„è§ˆéŸ³é¢‘ä¸‹è½½æˆåŠŸ")
                                        else:
                                            logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘ä¸‹è½½å¤±è´¥")

                                    # 2. ä¸‹è½½ RPP æ–‡ä»¶
                                    if local_data['rpp_file']:
                                        rpp_path = capsule_dir / local_data['rpp_file']
                                        logger.info(f"[SYNC]   â†’ ä¸‹è½½ RPP æ–‡ä»¶: {local_data['rpp_file']}")
                                        logger.info(f"[SYNC]     æ–‡ä»¶å¤¹: {local_data['file_path']}, ä½œè€…: {owner_id}, è·¯å¾„: {owner_id}/{local_data['file_path']}/project.rpp")
                                        if supabase.download_file(owner_id, local_data['file_path'], 'rpp', str(rpp_path)):
                                            logger.info(f"[SYNC]   âœ“ RPP æ–‡ä»¶ä¸‹è½½æˆåŠŸ")
                                        else:
                                            logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸‹è½½å¤±è´¥")

                                    # 3. ä¸‹è½½ Audio æ–‡ä»¶å¤¹ (å…ƒæ•°æ®åŒæ­¥æ—¶è·³è¿‡ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡å¯¼è‡´è¶…æ—¶)
                                    # logger.info(f"[SYNC]   â†’ ä¸‹è½½ Audio æ–‡ä»¶å¤¹...")
                                    # if supabase.download_file(owner_id, local_data['file_path'], 'audio_folder', str(capsule_dir)):
                                    #     logger.info(f"[SYNC]   âœ“ Audio æ–‡ä»¶å¤¹ä¸‹è½½æˆåŠŸ")
                                    # else:
                                    #     logger.warning(f"[SYNC]   âš  Audio æ–‡ä»¶å¤¹ä¸‹è½½å¤±è´¥")

                                    logger.info(f"[SYNC] âœ“ èƒ¶å›Šæ–‡ä»¶ä¸‹è½½å®Œæˆ: {local_data['name']}")

                                except Exception as e:
                                    logger.error(f"[SYNC] âœ— ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
                                    import traceback
                                    logger.error(traceback.format_exc())

                        db.conn.commit()
                    finally:
                        db.close()

            elif table_name == 'capsule_tags':
                records = supabase.download_tags(user_id)
            elif table_name == 'capsule_coordinates':
                records = supabase.download_coordinates(user_id)
            else:
                raise Exception(f"ä¸æ”¯æŒçš„è¡¨å: {table_name}")

            return jsonify({
                'success': True,
                'data': {
                    'records': records,
                    'deleted_ids': []
                }
            })

        except ImportError:
            raise Exception("Supabase SDK æœªå®‰è£…")
        except Exception as e:
            raise Exception(f"äº‘ç«¯ä¸‹è½½å¤±è´¥: {str(e)}")

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"ä»äº‘ç«¯ä¸‹è½½å¤±è´¥: {e}", 500)


@app.route('/api/sync/conflicts', methods=['GET'])
def get_conflicts():
    """
    è·å–æœªè§£å†³çš„å†²çªåˆ—è¡¨

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "conflicts": [...]
            }
        }
    """
    try:
        conn = sqlite3.connect(os.getenv('DATABASE_PATH', 'database/capsules.db').replace('sqlite:///', ''))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("""
            SELECT id, table_name, record_id, conflict_type, created_at
            FROM sync_conflicts
            WHERE resolved = 0
            ORDER BY created_at DESC
        """)

        conflicts = [dict(row) for row in cursor.fetchall()]
        conn.close()

        return jsonify({
            'success': True,
            'data': {
                'conflicts': conflicts,
                'count': len(conflicts)
            }
        })

    except Exception as e:
        raise APIError(f"è·å–å†²çªåˆ—è¡¨å¤±è´¥: {e}", 500)


@app.route('/api/sync/resolve-conflict', methods=['POST'])
@token_required
def resolve_conflict_endpoint(current_user):
    """
    è§£å†³å†²çª

    è¯·æ±‚ä½“:
        {
            "conflict_id": 1,
            "resolution": "local"  // "local", "cloud", "merge"
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "å†²çªå·²è§£å†³"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        conflict_id = data.get('conflict_id')
        resolution = data.get('resolution')

        if not all([conflict_id, resolution]):
            raise APIError('ç¼ºå°‘å¿…è¦å‚æ•°: conflict_id, resolution', 400)

        if resolution not in ['local', 'cloud', 'merge']:
            raise APIError('æ— æ•ˆçš„è§£å†³æ–¹æ¡ˆ', 400)

        sync_service = get_sync_service()
        success = sync_service.resolve_conflict(conflict_id, resolution)

        if success:
            return jsonify({
                'success': True,
                'message': 'å†²çªå·²è§£å†³'
            })
        else:
            raise APIError('è§£å†³å†²çªå¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è§£å†³å†²çªå¤±è´¥: {e}", 500)


# ============================================
# Phase B.4: è½»é‡çº§åŒæ­¥ APIï¼ˆå…ƒæ•°æ® + é¢„è§ˆéŸ³é¢‘ï¼‰
# ============================================

@app.route('/api/sync/lightweight', methods=['POST'])
@token_required
def sync_metadata_lightweight(current_user):
    """
    è½»é‡çº§åŒæ­¥ï¼šä»…åŒæ­¥å…ƒæ•°æ® + é¢„è§ˆéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰

    Phase B.4 æ–°å¢åŠŸèƒ½ï¼šåˆ†ç¦»å…ƒæ•°æ®å’Œèµ„äº§åŒæ­¥

    è¯·æ±‚ä½“:
        {
            "include_previews": true,  // æ˜¯å¦è‡ªåŠ¨ä¸‹è½½é¢„è§ˆéŸ³é¢‘
            "force": false              // æ˜¯å¦å¼ºåˆ¶åŒæ­¥ï¼ˆå¿½ç•¥æœ¬åœ°ç¼“å­˜ï¼‰
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "synced_count": 10,
                "preview_downloaded": 5,
                "duration_seconds": 2.5,
                "errors": []
            }
        }
    """
    try:
        data = request.get_json() or {}
        include_previews = data.get('include_previews', True)
        force = data.get('force', False)

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ”„ è½»é‡çº§åŒæ­¥è¯·æ±‚")
        logger.info("=" * 60)
        logger.info(f"ç”¨æˆ·: {current_user.get('username')}")
        logger.info(f"åŒ…å«é¢„è§ˆéŸ³é¢‘: {include_previews}")
        logger.info(f"å¼ºåˆ¶åŒæ­¥: {force}")
        logger.info()

        # è·å–ç”¨æˆ· ID
        user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

        if not user_id:
            raise APIError('ç”¨æˆ· ID ä¸å­˜åœ¨', 400)

        # è·å–åŒæ­¥æœåŠ¡å®ä¾‹
        sync_service = get_sync_service()

        # æ‰§è¡Œè½»é‡çº§åŒæ­¥
        result = sync_service.sync_metadata_lightweight(
            user_id=user_id,
            include_previews=include_previews
        )

        # åŒæ—¶ä¹ŸåŒæ­¥æ£±é•œé…ç½® (Phase C)
        try:
            sync_service.sync_prisms(user_id)
        except Exception as e:
            logger.warning(f"æ£±é•œåŒæ­¥å¤±è´¥ (éé˜»æ–­): {e}")

        if result['success']:
            logger.info(f"âœ… è½»é‡çº§åŒæ­¥æˆåŠŸ: {result['synced_count']} ä¸ªèƒ¶å›Š")
            return jsonify({
                'success': True,
                'data': {
                    'synced_count': result['synced_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            })
        else:
            logger.warning(f"âš ï¸  è½»é‡çº§åŒæ­¥éƒ¨åˆ†å¤±è´¥: {len(result['errors'])} ä¸ªé”™è¯¯")
            return jsonify({
                'success': False,
                'error': 'åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯',
                'data': {
                    'synced_count': result['synced_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            }), 207  # 207 Multi-Statusï¼ˆéƒ¨åˆ†æˆåŠŸï¼‰

    except APIError:
        raise
    except Exception as e:
        logger.error(f"è½»é‡çº§åŒæ­¥å¤±è´¥: {e}")
        raise APIError(f"è½»é‡çº§åŒæ­¥å¤±è´¥: {e}", 500)


# ============================================
# Phase B: æ··åˆå­˜å‚¨ç­–ç•¥ - ä¸‹è½½ç®¡ç† API
# ============================================

@app.route('/api/capsules/<int:capsule_id>/download-wav', methods=['POST'])
def download_wav(capsule_id):
    """
    æŒ‰éœ€ä¸‹è½½ WAV æºæ–‡ä»¶ï¼ˆPhase Bï¼‰

    è¯·æ±‚ä½“:
        {
            "force": false,  // æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            "priority": 5    // ä¼˜å…ˆçº§ (0-10)
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "task_id": 123,
            "status": "pending",  // pending, downloading, completed
            "progress": 0,
            "file_size": 104857600
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        data = request.get_json() or {}
        force = data.get('force', False)
        priority = data.get('priority', 5)

        db = get_database()

        # è·å–èƒ¶å›Šä¿¡æ¯
        capsule = db.get_capsule(capsule_id)
        if not capsule:
            raise APIError('èƒ¶å›Šä¸å­˜åœ¨', 404)

        # æ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜
        if not force:
            cache_entry = db.get_cache_entry(capsule_id, 'wav')
            if cache_entry and Path(cache_entry['file_path']).exists():
                return jsonify({
                    'success': True,
                    'already_cached': True,
                    'file_path': cache_entry['file_path'],
                    'file_size': cache_entry['file_size']
                })

        # ä» Supabase è·å–ä¸‹è½½ URL
        # TODO: è¿™é‡Œéœ€è¦é›†æˆ Supabase Storage API
        # æš‚æ—¶è¿”å›å ä½å“åº”
        raise APIError('WAV ä¸‹è½½åŠŸèƒ½å¾…é›†æˆ Supabase Storage', 501)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"åˆ›å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}", 500)


@app.route('/api/capsules/<int:capsule_id>/download-status', methods=['GET'])
def get_download_status(capsule_id):
    """
    è·å–èƒ¶å›Šä¸‹è½½çŠ¶æ€ï¼ˆPhase Bï¼‰

    å“åº”:
        {
            "status": "downloading",  // pending, downloading, completed, failed
            "progress": 45,
            "downloaded_bytes": 47185920,
            "speed": 2621440,  // bytes/second
            "eta": "23s"
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        db = get_database()

        # è·å–ä¸‹è½½ä»»åŠ¡
        tasks = db.get_download_tasks_by_capsule(capsule_id)

        if not tasks:
            return jsonify({
                'status': 'not_started',
                'progress': 0
            })

        # è·å–æœ€æ–°çš„ä¸‹è½½ä»»åŠ¡
        task = tasks[0]

        # æ ¼å¼åŒ–å“åº”
        response = {
            'task_id': task['id'],
            'status': task['status'],
            'progress': task['progress'],
            'downloaded_bytes': task['downloaded_bytes'],
            'remote_size': task['remote_size']
        }

        if task['speed']:
            response['speed'] = task['speed']
            response['speed_mb_s'] = f"{task['speed'] / 1024 / 1024:.2f} MB/s"

        if task['eta_seconds']:
            response['eta'] = f"{task['eta_seconds']}s"
            response['eta_seconds'] = task['eta_seconds']

        if task['error_message']:
            response['error'] = task['error_message']

        return jsonify(response)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å–ä¸‹è½½çŠ¶æ€å¤±è´¥: {e}", 500)


@app.route('/api/download-tasks/<int:task_id>/pause', methods=['POST'])
def pause_download_task(task_id):
    """
    æš‚åœä¸‹è½½ä»»åŠ¡ï¼ˆPhase Bï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "ä¸‹è½½å·²æš‚åœ"
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        db = get_database()

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæš‚åœ
        success = db.update_download_task_status(task_id, 'paused')

        if success:
            return jsonify({
                'success': True,
                'message': 'ä¸‹è½½å·²æš‚åœ'
            })
        else:
            raise APIError('æš‚åœä¸‹è½½å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æš‚åœä¸‹è½½å¤±è´¥: {e}", 500)


@app.route('/api/download-tasks/<int:task_id>/resume', methods=['POST'])
def resume_download_task(task_id):
    """
    æ¢å¤ä¸‹è½½ä»»åŠ¡ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰ï¼ˆPhase Bï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "ä¸‹è½½å·²æ¢å¤"
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        db = get_database()

        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = db.get_download_task(task_id)
        if not task:
            raise APIError('ä»»åŠ¡ä¸å­˜åœ¨', 404)

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if task['status'] not in ['paused', 'failed']:
            raise APIError(f'ä»»åŠ¡çŠ¶æ€ä¸º {task["status"]}ï¼Œæ— æ³•æ¢å¤', 400)

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º pending
        success = db.update_download_task_status(task_id, 'pending')

        if success:
            # TODO: è¿™é‡Œéœ€è¦é€šçŸ¥ DownloadQueue é‡æ–°å¤„ç†ä»»åŠ¡
            return jsonify({
                'success': True,
                'message': 'ä¸‹è½½å·²æ¢å¤'
            })
        else:
            raise APIError('æ¢å¤ä¸‹è½½å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æ¢å¤ä¸‹è½½å¤±è´¥: {e}", 500)


@app.route('/api/download-tasks/<int:task_id>/cancel', methods=['POST'])
def cancel_download_task(task_id):
    """
    å–æ¶ˆä¸‹è½½ä»»åŠ¡ï¼ˆPhase Bï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "ä¸‹è½½å·²å–æ¶ˆ"
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        db = get_database()

        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = db.get_download_task(task_id)
        if not task:
            raise APIError('ä»»åŠ¡ä¸å­˜åœ¨', 404)

        # å–æ¶ˆä»»åŠ¡
        success = db.update_download_task_status(task_id, 'cancelled')

        if success:
            # TODO: å¦‚æœä»»åŠ¡æ­£åœ¨ä¸‹è½½ï¼Œéœ€è¦é€šçŸ¥ DownloadWorker åœæ­¢
            # åˆ é™¤éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶
            if task['local_path'] and Path(task['local_path']).exists():
                try:
                    os.remove(task['local_path'])
                    logger.info(f"å·²åˆ é™¤éƒ¨åˆ†ä¸‹è½½æ–‡ä»¶: {task['local_path']}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤éƒ¨åˆ†ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")

            return jsonify({
                'success': True,
                'message': 'ä¸‹è½½å·²å–æ¶ˆ'
            })
        else:
            raise APIError('å–æ¶ˆä¸‹è½½å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"å–æ¶ˆä¸‹è½½å¤±è´¥: {e}", 500)


@app.route('/api/cache/stats', methods=['GET'])
def get_cache_stats():
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆPhase Bï¼‰

    å“åº”:
        {
            "total_cached_files": 50,
            "total_cache_size": 1073741824,
            "max_cache_size": 5368709120,
            "usage_percent": 20.0,
            "available_space": 4294967296,
            "needs_purge": false,
            "pinned_files_count": 5,
            "pinned_files_size": 104857600,
            "by_type": {
                "preview": {"count": 50, "size": 52428800},
                "wav": {"count": 20, "size": 1024*1024*100}
            }
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        from cache_manager import create_cache_manager

        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        max_cache_size = int(os.getenv('MAX_CACHE_SIZE', 5 * 1024 * 1024 * 1024))  # 5GB
        manager = create_cache_manager(
            db_path=get_database().db_path.replace('sqlite:///', ''),
            max_cache_size=max_cache_size
        )

        # è·å–ç¼“å­˜çŠ¶æ€
        status = manager.get_cache_status()

        return jsonify(status)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}", 500)


@app.route('/api/cache/purge', methods=['POST'])
def purge_cache():
    """
    æ¸…ç†ç¼“å­˜ï¼ˆPhase Bï¼‰

    è¯·æ±‚ä½“:
        {
            "keep_pinned": true,
            "max_size_to_free": 536870912  // å¯é€‰ï¼Œé‡Šæ”¾çš„æœ€å¤§ç©ºé—´
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "files_deleted": 10,
            "space_freed": 104857600,
            "files_skipped": 5,
            "errors": []
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        data = request.get_json() or {}
        keep_pinned = data.get('keep_pinned', True)
        max_size_to_free = data.get('max_size_to_free')

        from cache_manager import create_cache_manager

        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        max_cache_size = int(os.getenv('MAX_CACHE_SIZE', 5 * 1024 * 1024 * 1024))  # 5GB
        manager = create_cache_manager(
            db_path=get_database().db_path.replace('sqlite:///', ''),
            max_cache_size=max_cache_size
        )

        # æ‰§è¡Œæ¸…ç†
        result = manager.purge_old_cache(
            keep_pinned=keep_pinned,
            max_size_to_free=max_size_to_free
        )

        return jsonify({
            'success': True,
            **result
        })

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}", 500)


@app.route('/api/capsules/<int:capsule_id>/cache-pin', methods=['PUT'])
def set_cache_pinned(capsule_id):
    """
    è®¾ç½®ç¼“å­˜å›ºå®šçŠ¶æ€ï¼ˆPhase Bï¼‰

    è¯·æ±‚ä½“:
        {
            "pinned": true  // true = å›ºå®š, false = å–æ¶ˆå›ºå®š
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "ç¼“å­˜å·²å›ºå®š"
        }
    """
    try:
        # éªŒè¯ç”¨æˆ·å·²ç™»å½•
        auth_manager = get_auth_manager()
        user_id = auth_manager.verify_token(request)

        if not user_id:
            raise APIError('æœªæˆæƒè®¿é—®', 401)

        data = request.get_json()
        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        pinned = data.get('pinned')
        if pinned is None:
            raise APIError('ç¼ºå°‘å‚æ•°: pinned', 400)

        db = get_database()
        success = db.set_cache_pinned(capsule_id, pinned)

        if success:
            action = 'å›ºå®š' if pinned else 'å–æ¶ˆå›ºå®š'
            return jsonify({
                'success': True,
                'message': f'ç¼“å­˜å·²{action}'
            })
        else:
            raise APIError('è®¾ç½®å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è®¾ç½®ç¼“å­˜å›ºå®šçŠ¶æ€å¤±è´¥: {e}", 500)


@app.route('/api/capsules/<int:capsule_id>/asset-status', methods=['GET'])
@token_required
def get_asset_status(current_user, capsule_id):
    """
    è·å–èƒ¶å›Šèµ„äº§çŠ¶æ€ï¼ˆPhase Bï¼‰

    å“åº”:
        {
            "capsule_id": 1,
            "asset_status": "local",  // local, cloud_only, downloading, cached
            "cloud_status": "synced",
            "local_wav_path": "/path/to/file.wav",
            "local_wav_size": 1330486,
            "download_progress": 0,
            "is_cache_pinned": false
        }
    """
    try:
        db = get_database()
        asset_status = db.get_capsule_asset_status(capsule_id)

        if not asset_status:
            raise APIError('èƒ¶å›Šä¸å­˜åœ¨', 404)

        return jsonify(asset_status)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è·å–èµ„äº§çŠ¶æ€å¤±è´¥: {e}", 500)


# ============================================
# Phase B.5: æ™ºèƒ½ç¼“å­˜ç®¡ç† API
# ============================================

@app.route('/api/cache/smart-purge', methods=['POST'])
@token_required
def smart_cache_purge(current_user):
    """
    æ™ºèƒ½ç¼“å­˜æ¸…ç†ï¼ˆPhase B.5ï¼‰

    ç»¼åˆè€ƒè™‘ LRUã€è®¿é—®é¢‘ç‡ã€æ–‡ä»¶å¤§å°ã€å›ºå®šçŠ¶æ€ç­‰å› ç´ 

    è¯·æ±‚ä½“:
        {
            "target_usage_percent": 80.0,  // ç›®æ ‡ä½¿ç”¨ç‡ï¼ˆé»˜è®¤ 80%ï¼‰
            "keep_frequent": true,          // æ˜¯å¦ä¿ç•™é«˜é¢‘è®¿é—®æ–‡ä»¶
            "min_access_count": 3            // æœ€å°è®¿é—®æ¬¡æ•°é˜ˆå€¼
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "files_deleted": 5,
                "space_freed": 52428800,
                "files_skipped": 2,
                "errors": []
            }
        }
    """
    try:
        data = request.get_json() or {}
        target_usage_percent = data.get('target_usage_percent', 80.0)
        keep_frequent = data.get('keep_frequent', True)
        min_access_count = data.get('min_access_count', 3)

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§  æ™ºèƒ½ç¼“å­˜æ¸…ç†è¯·æ±‚")
        logger.info("=" * 60)
        logger.info(f"ç”¨æˆ·: {current_user.get('username')}")
        logger.info(f"ç›®æ ‡ä½¿ç”¨ç‡: {target_usage_percent}%")
        logger.info(f"ä¿ç•™é«˜é¢‘æ–‡ä»¶: {keep_frequent}")
        logger.info(f"æœ€å°è®¿é—®æ¬¡æ•°: {min_access_count}")
        logger.info()

        # å¯¼å…¥ CacheManager
        from cache_manager import create_cache_manager

        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        cache_manager = create_cache_manager()

        # æ‰§è¡Œæ™ºèƒ½æ¸…ç†
        result = cache_manager.smart_cache_cleanup(
            target_usage_percent=target_usage_percent,
            keep_frequent=keep_frequent,
            min_access_count=min_access_count
        )

        logger.info(f"âœ… æ™ºèƒ½æ¸…ç†å®Œæˆ: åˆ é™¤ {result['files_deleted']} ä¸ªæ–‡ä»¶, é‡Šæ”¾ {cache_manager._format_size(result['space_freed'])}")

        return jsonify({
            'success': True,
            'data': {
                'files_deleted': result['files_deleted'],
                'space_freed': result['space_freed'],
                'files_skipped': result['files_skipped'],
                'errors': result['errors']
            }
        })

    except APIError:
        raise
    except Exception as e:
        logger.error(f"æ™ºèƒ½ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
        raise APIError(f"æ™ºèƒ½ç¼“å­˜æ¸…ç†å¤±è´¥: {e}", 500)


# ============================================
# Phase C1: æ£±é•œé…ç½®ç®¡ç† API
# ============================================

@app.route('/api/prisms', methods=['GET'])
def get_prisms():
    """
    è·å–æ‰€æœ‰æ´»è·ƒæ£±é•œé…ç½®

    Phase C1: æ£±é•œç‰ˆæœ¬æ§åˆ¶

    æ— éœ€è®¤è¯

    å“åº”:
        [
            {
                "id": "texture",
                "name": "Texture / Timbre (è´¨æ„Ÿ)",
                "description": "...",
                "axis_config": {...},
                "anchors": [...],
                "version": 1,
                "updated_at": "2026-01-11 10:00:00",
                "updated_by": "alice"
            },
            ...
        ]
    """
    try:
        prisms = prism_manager.get_all_prisms()

        # è§£æ JSON å­—æ®µ
        for p in prisms:
            try:
                p['axis_config'] = json.loads(p['axis_config'])
                p['anchors'] = json.loads(p['anchors'])
                p['field_data'] = json.loads(p.get('field_data', '[]'))
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"æ£±é•œ {p.get('id')} çš„ JSON å­—æ®µè§£æå¤±è´¥: {e}")
                p['axis_config'] = {}
                p['anchors'] = []
                p['field_data'] = []

        return jsonify(prisms)

    except Exception as e:
        logger.error(f"è·å–æ£±é•œåˆ—è¡¨å¤±è´¥: {e}")
        # è¿™é‡Œå‡è®¾ APIError å·²åœ¨ä¸Šä¸‹æ–‡å®šä¹‰ï¼Œå¦‚æœæ²¡æœ‰å®šä¹‰åˆ™ç›´æ¥æŠ›å‡ºæˆ–è¿”å› 500
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/prisms/field', methods=['GET'])
def get_prisms_field():
    """
    è·å–æ‰€æœ‰æ£±é•œçš„é¢„è®¡ç®—åŠ›åœºåæ ‡ (WebApp æ ¸å¿ƒåŠ è½½æ¥å£)
    
    æ ¼å¼å…¼å®¹ sonic_vectors.json
    """
    try:
        prisms = prism_manager.get_all_prisms()
        output = {}
        for p in prisms:
            try:
                output[p['id']] = {
                    "name": p['name'],
                    "description": p['description'],
                    "axes": json.loads(p.get('axis_config', '{}')),
                    "points": json.loads(p.get('field_data', '[]'))
                }
            except Exception as e:
                logger.warning(f"è§£ææ£±é•œ {p.get('id')} å­—æ®µå¤±è´¥: {e}")
                
        return jsonify(output)
    except Exception as e:
        logger.error(f"è·å–åŠ›åœºæ•°æ®å¤±è´¥: {e}")
        return jsonify({"success": False, "error": str(e)})


@app.route('/api/prisms/<prism_id>', methods=['GET'])
def get_prism_detail(prism_id):
    """
    è·å–å•ä¸ªæ£±é•œè¯¦æƒ…

    Phase C1: æ£±é•œç‰ˆæœ¬æ§åˆ¶

    Args:
        prism_id: æ£±é•œ ID (å¦‚ 'texture', 'source')

    æ— éœ€è®¤è¯

    å“åº”:
        {
            "id": "texture",
            "name": "Texture / Timbre (è´¨æ„Ÿ)",
            "description": "...",
            "axis_config": {
                "x_label_pos": "Rough",
                "x_label_neg": "Smooth",
                ...
            },
            "anchors": [
                {"word": "ç²—ç³™", "x": 80, "y": 50},
                ...
            ],
            "version": 5,
            "updated_at": "2026-01-11 10:00:00",
            "updated_by": "alice"
        }
    """
    try:
        prism = prism_manager.get_prism(prism_id)

        if not prism:
            raise APIError(f"æ£±é•œ '{prism_id}' ä¸å­˜åœ¨", 404)

        # è§£æ JSON å­—æ®µ
        try:
            prism['axis_config'] = json.loads(prism['axis_config'])
            prism['anchors'] = json.loads(prism['anchors'])
        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"æ£±é•œ {prism_id} çš„ JSON å­—æ®µè§£æå¤±è´¥: {e}")
            prism['axis_config'] = {}
            prism['anchors'] = []

        return jsonify(prism)

    except APIError:
        raise
    except Exception as e:
        logger.error(f"è·å–æ£±é•œè¯¦æƒ…å¤±è´¥: {e}")
        raise APIError(f"è·å–æ£±é•œè¯¦æƒ…å¤±è´¥: {e}", 500)


@app.route('/api/prisms/<prism_id>', methods=['POST', 'PUT'])
@token_required
def update_prism(current_user, prism_id):
    """
    æ›´æ–°æ£±é•œé…ç½®ï¼ˆè‡ªåŠ¨ç‰ˆæœ¬æ§åˆ¶ï¼‰

    Phase C1: æ£±é•œç‰ˆæœ¬æ§åˆ¶

    ç­–ç•¥: Last Write Wins
    - æ¯æ¬¡æ›´æ–°è‡ªåŠ¨é€’å¢ç‰ˆæœ¬å·
    - ä¿å­˜å®Œæ•´å¿«ç…§åˆ° prism_versions è¡¨
    - è®°å½•æ›´æ–°è€…å’Œæ—¶é—´æˆ³

    Args:
        prism_id: æ£±é•œ ID (å¦‚ 'texture', 'source')

    è¯·æ±‚ä½“:
        {
            "name": "Texture / Timbre (è´¨æ„Ÿ)",
            "description": "æè¿°å£°éŸ³çš„è´¨æ„Ÿç‰¹å¾",
            "axis_config": {
                "x_label_pos": "Rough",
                "x_label_neg": "Smooth",
                "y_label_pos": "Bright",
                "y_label_neg": "Dark"
            },
            "anchors": [
                {"word": "ç²—ç³™", "x": 80, "y": 50},
                {"word": "å…‰æ»‘", "x": -80, "y": 50}
            ]
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "Prism updated successfully",
            "data": {
                "id": "texture",
                "version": 6,
                "updated_at": "2026-01-11 10:05:00"
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError("è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º", 400)

        # éªŒè¯å¿…è¦å­—æ®µ
        if 'name' not in data:
            raise APIError("ç¼ºå°‘å¿…è¦å­—æ®µ: name", 400)

        # è·å–ç”¨æˆ· ID
        user_id = current_user.get('username') or current_user.get('user_id', 'unknown')

        logger.info(f"ç”¨æˆ· {user_id} æ›´æ–°æ£±é•œ {prism_id}")

        # æ›´æ–°æ£±é•œï¼ˆè‡ªåŠ¨ç‰ˆæœ¬æ§åˆ¶ï¼‰
        new_version = prism_manager.create_or_update_prism(
            prism_id,
            data,
            user_id=user_id
        )

        return jsonify({
            'success': True,
            'message': f"æ£±é•œ '{prism_id}' æ›´æ–°æˆåŠŸ",
            'data': {
                'id': prism_id,
                'version': new_version,
                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        })

    except APIError:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°æ£±é•œå¤±è´¥: {e}")
        raise APIError(f"æ›´æ–°æ£±é•œå¤±è´¥: {e}", 500)


@app.route('/api/prisms/<prism_id>/history', methods=['GET'])
@token_required
def get_prism_history(current_user, prism_id):
    """
    è·å–æ£±é•œç‰ˆæœ¬å†å²

    Phase C1: æ£±é•œç‰ˆæœ¬æ§åˆ¶

    Args:
        prism_id: æ£±é•œ ID (å¦‚ 'texture')

    æŸ¥è¯¢å‚æ•°:
        limit: è¿”å›çš„æœ€å¤§ç‰ˆæœ¬æ•°ï¼ˆé»˜è®¤ 10ï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        [
            {
                "version": 5,
                "created_at": "2026-01-11 10:00:00",
                "created_by": "alice",
                "change_reason": "update"
            },
            {
                "version": 4,
                "created_at": "2026-01-11 09:55:00",
                "created_by": "bob",
                "change_reason": "update"
            },
            ...
        ]
    """
    try:
        # æ£€æŸ¥æ£±é•œæ˜¯å¦å­˜åœ¨
        prism = prism_manager.get_prism(prism_id)
        if not prism:
            raise APIError(f"æ£±é•œ '{prism_id}' ä¸å­˜åœ¨", 404)

        # è·å–ç‰ˆæœ¬å†å²
        history = prism_manager.get_version_history(prism_id)

        # åº”ç”¨ limit
        limit = request.args.get('limit', type=int, default=10)
        if limit > 0:
            history = history[:limit]

        return jsonify(history)

    except APIError:
        raise
    except Exception as e:
        logger.error(f"è·å–ç‰ˆæœ¬å†å²å¤±è´¥: {e}")
        raise APIError(f"è·å–ç‰ˆæœ¬å†å²å¤±è´¥: {e}", 500)


@app.route('/api/prisms/<prism_id>/rollback', methods=['POST'])
@token_required
def rollback_prism(current_user, prism_id):
    """
    å›æ»šæ£±é•œåˆ°æŒ‡å®šç‰ˆæœ¬

    Phase C1: æ£±é•œç‰ˆæœ¬æ§åˆ¶

    æ³¨æ„ï¼šå›æ»šä¼šåˆ›å»ºä¸€ä¸ªæ–°ç‰ˆæœ¬ï¼Œè€Œéè¦†ç›–å†å²
    ä¾‹å¦‚ï¼šå½“å‰ v5ï¼Œå›æ»šåˆ° v3 â†’ åˆ›å»º v6ï¼ˆå†…å®¹ç­‰äº v3ï¼‰

    Args:
        prism_id: æ£±é•œ ID (å¦‚ 'texture')

    è¯·æ±‚ä½“:
        {
            "version": 3  // ç›®æ ‡ç‰ˆæœ¬å·
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "å·²å›æ»šåˆ° v3",
            "data": {
                "id": "texture",
                "target_version": 3,
                "new_version": 6,
                "rolled_back_at": "2026-01-11 10:10:00"
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError("è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º", 400)

        target_version = data.get('version')

        if target_version is None:
            raise APIError("ç¼ºå°‘ç›®æ ‡ç‰ˆæœ¬å·: version", 400)

        # æ£€æŸ¥æ£±é•œæ˜¯å¦å­˜åœ¨
        prism = prism_manager.get_prism(prism_id)
        if not prism:
            raise APIError(f"æ£±é•œ '{prism_id}' ä¸å­˜åœ¨", 404)

        # è·å–ç”¨æˆ· ID
        user_id = current_user.get('username') or current_user.get('user_id', 'unknown')

        logger.info(f"ç”¨æˆ· {user_id} å›æ»šæ£±é•œ {prism_id} åˆ° v{target_version}")

        # æ‰§è¡Œå›æ»š
        success, message = prism_manager.restore_version(prism_id, target_version)

        if not success:
            raise APIError(message, 400)

        # è·å–æ–°ç‰ˆæœ¬å·
        updated_prism = prism_manager.get_prism(prism_id)

        return jsonify({
            'success': True,
            'message': message,
            'data': {
                'id': prism_id,
                'target_version': target_version,
                'new_version': updated_prism['version'],
                'rolled_back_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        })

    except APIError:
        raise
    except Exception as e:
        logger.error(f"å›æ»šæ£±é•œå¤±è´¥: {e}")
        raise APIError(f"å›æ»šæ£±é•œå¤±è´¥: {e}", 500)


@app.route('/api/embed/coordinate', methods=['POST'])
def calculate_coordinate_api():
    """
    è®¡ç®—æ–‡æœ¬åæ ‡ (Phase C3: Hybrid Embedding)
    
    è¯·æ±‚ä½“:
        {
            "text": "æ˜äº®çš„å£°éŸ³",
            "prism_id": "texture"
        }
    """
    try:
        # æ£€æŸ¥ ML åŠŸèƒ½æ˜¯å¦å¯ç”¨
        if not ML_AVAILABLE:
            raise APIError("ML åŠŸèƒ½ä¸å¯ç”¨ï¼ˆç¼ºå°‘ numpy/sklearn/sentence-transformers ä¾èµ–ï¼‰", 503)
        
        data = request.get_json()
        if not data or 'text' not in data or 'prism_id' not in data:
            raise APIError("ç¼ºå°‘å¿…è¦å‚æ•°: text, prism_id", 400)
            
        text = data['text']
        prism_id = data['prism_id']
        
        service = get_hybrid_service()
        result = service.get_coordinate(text, prism_id)
        
        if result:
            return jsonify({
                "success": True,
                "text": text,
                "prism_id": prism_id,
                "x": result['x'],
                "y": result['y']
            })
        else:
            raise APIError("åæ ‡è®¡ç®—å¤±è´¥", 500)
            
    except APIError:
        raise
    except Exception as e:
        logger.error(f"Embedding è®¡ç®—å¤±è´¥: {e}")
        raise APIError(f"Embedding è®¡ç®—å¤±è´¥: {e}", 500)

# ============================================
# é…ç½®ç®¡ç†ç«¯ç‚¹
# ============================================

@app.route('/api/config/save', methods=['POST'])
def save_config():
    """
    ä¿å­˜ç”¨æˆ·é…ç½®ï¼ˆæ— éœ€è®¤è¯ï¼‰

    ç”¨äºå‰ç«¯ä¿å­˜ Tauri é…ç½®æ—¶åŒæ­¥åˆ° Python åç«¯

    è¯·æ±‚ä½“:
        {
            "export_dir": "/path/to/export/dir",
            "reaper_path": "/path/to/reaper"
        }

    å“åº”:
        {
            "success": true,
            "message": "é…ç½®å·²ä¿å­˜"
        }
    """
    logger.info("[DEBUG] /api/config/save ç«¯ç‚¹è¢«è°ƒç”¨")
    try:
        data = request.get_json()
        logger.info(f"[DEBUG] æ¥æ”¶åˆ°çš„æ•°æ®: {data}")

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        export_dir = data.get('export_dir')
        reaper_path = data.get('reaper_path')

        # ä¿å­˜é…ç½®åˆ°ç³»ç»Ÿé…ç½®ç›®å½•ï¼ˆä¸ capsule_scanner.py ç›¸åŒçš„è·¯å¾„ï¼‰
        from pathlib import Path
        import os

        home = Path.home()
        system = os.uname().sysname.lower() if hasattr(os, 'uname') else 'unknown'

        if 'darwin' in system:
            # macOS
            config_dir = home / 'Library/Application Support/com.soundcapsule.app'
        elif 'windows' in system or os.name == 'nt':
            # Windows
            appdata = os.environ.get('APPDATA', home / 'AppData/Roaming')
            config_dir = Path(appdata) / 'com.soundcapsule.app'
        else:
            # Linux
            config_dir = home / '.config/com.soundcapsule.app'

        config_file = config_dir / 'config.json'

        # è¯»å–ç°æœ‰é…ç½®
        existing_config = {}
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                existing_config = json.load(f)

        # æ£€æµ‹å¯¼å‡ºç›®å½•æ˜¯å¦å˜æ›´ï¼ˆåœ¨æ›´æ–°ä¹‹å‰ï¼‰
        export_dir_changed = False
        old_export_dir = existing_config.get('export_dir')

        # æ›´æ–°é…ç½®
        if export_dir:
            existing_config['export_dir'] = export_dir
            # åŒæ—¶æ›´æ–°ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ get_output_dir() èƒ½ç«‹å³è·å–æœ€æ–°å€¼
            os.environ['SYNESTH_CAPSULE_OUTPUT'] = export_dir
            logger.info(f"[CONFIG] ä¿å­˜å¯¼å‡ºç›®å½•å¹¶æ›´æ–°ç¯å¢ƒå˜é‡: {export_dir}")

        if reaper_path:
            existing_config['reaper_path'] = reaper_path
            logger.info(f"[CONFIG] ä¿å­˜ REAPER è·¯å¾„: {reaper_path}")

        if export_dir and old_export_dir and export_dir != old_export_dir:
            export_dir_changed = True
            logger.warning(f"[CONFIG] å¯¼å‡ºç›®å½•å·²å˜æ›´: '{old_export_dir}' -> '{export_dir}'")
            logger.info(f"[DEBUG] è·¯å¾„å˜æ›´æ£€æµ‹å®Œæˆ")
            
            # âš ï¸ ä¸´æ—¶ç¦ç”¨æ–‡ä»¶å¤åˆ¶åŠŸèƒ½ï¼Œé¿å…è§¦å‘åº”ç”¨é‡å¯
            logger.info(f"[CONFIG] è·³è¿‡æ–‡ä»¶å¤åˆ¶ï¼ˆå·²ç¦ç”¨ï¼‰")

        # ä¿å­˜é…ç½®
        logger.info(f"[DEBUG] å‡†å¤‡å†™å…¥é…ç½®æ–‡ä»¶: {config_file}")
        config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(existing_config, f, indent=2, ensure_ascii=False)

        logger.info(f"[CONFIG] é…ç½®å·²ä¿å­˜åˆ°: {config_file}")
        logger.info(f"[DEBUG] /api/config/save å³å°†è¿”å›å“åº”")

        return jsonify({
            'success': True,
            'message': 'é…ç½®å·²ä¿å­˜' + ('ï¼Œæ—§ç›®å½•æ–‡ä»¶å·²å¤åˆ¶åˆ°æ–°ç›®å½•' if export_dir_changed else ''),
            'directory_changed': export_dir_changed
        })

    except APIError:
        raise
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        raise APIError(f"ä¿å­˜é…ç½®å¤±è´¥: {e}", 500)


@app.route('/api/config/reset-local-db', methods=['POST'])
def reset_local_db():
    """
    æ¸…ç©ºæœ¬åœ°æ•°æ®åº“ï¼ˆä¿ç•™ç”¨æˆ·è®¤è¯ä¿¡æ¯ï¼‰
    
    ç”¨äºè·¯å¾„å˜æ›´æ—¶æ¸…ç©ºæœ¬åœ°ç¼“å­˜ï¼Œä¹‹åéœ€è¦é‡æ–°åŒæ­¥
    
    å“åº”:
        {
            "success": true,
            "message": "æœ¬åœ°æ•°æ®åº“å·²æ¸…ç©º",
            "deleted": {
                "capsules": 10,
                "tags": 25,
                "coordinates": 20,
                "sync_status": 10
            }
        }
    """
    try:
        logger.info("[CONFIG] å¼€å§‹æ¸…ç©ºæœ¬åœ°æ•°æ®åº“...")
        
        db = get_database()
        deleted_counts = db.clear_all_capsules()
        
        logger.info(f"[CONFIG] æœ¬åœ°æ•°æ®åº“å·²æ¸…ç©º: {deleted_counts}")
        
        return jsonify({
            'success': True,
            'message': 'æœ¬åœ°æ•°æ®åº“å·²æ¸…ç©ºï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶å°†é‡æ–°åŒæ­¥',
            'deleted': deleted_counts
        })
        
    except Exception as e:
        logger.error(f"æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}")
        raise APIError(f"æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}", 500)


# ============================================
# ä¸»å‡½æ•°
# ============================================

if __name__ == '__main__':
    # åˆå§‹åŒ–æ•°æ®åº“
    db = get_database()
    db_path = db.db_path.replace('sqlite:///', '')

    if not Path(db_path).exists():
        print("æ•°æ®åº“ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
        db.initialize()
    else:
        # Phase G: æ•°æ®åº“å¥åº·æ£€æŸ¥ï¼ˆç”Ÿäº§ç¯å¢ƒé€‚ç”¨ï¼‰
        print("æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§...")
        health = db.verify_schema()
        
        if not health['valid']:
            print(f"âš ï¸  æ•°æ®åº“ schema ä¸å®Œæ•´:")
            print(f"   å½“å‰å­—æ®µ: {health['current_fields_count']}")
            print(f"   éœ€è¦å­—æ®µ: {health['required_fields_count']}")
            
            if health['missing_fields']:
                print(f"   ç¼ºå¤±å­—æ®µ: {', '.join(health['missing_fields'])}")
            if health['missing_tables']:
                print(f"   ç¼ºå¤±è¡¨: {', '.join(health['missing_tables'])}")
            
            if health.get('invalid_tables'):
                print(f"   ç»“æ„é”™è¯¯çš„è¡¨: {', '.join(health['invalid_tables'])}")
            
            print("\nğŸ”§ æ­£åœ¨è‡ªåŠ¨ä¿®å¤...")
            
            import sqlite3
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # ä¿®å¤ç»“æ„é”™è¯¯çš„è¡¨ï¼ˆåˆ é™¤å¹¶é‡å»ºï¼‰
            invalid_tables = health.get('invalid_tables', [])
            for table in invalid_tables:
                try:
                    cursor.execute(f"DROP TABLE IF EXISTS {table}")
                    print(f"   âœ“ åˆ é™¤æ—§è¡¨: {table}")
                except Exception as e:
                    print(f"   âœ— åˆ é™¤è¡¨ {table} å¤±è´¥: {e}")
            
            # åˆ›å»ºç¼ºå¤±çš„è¡¨ï¼ˆåŒ…æ‹¬åˆšåˆ é™¤çš„æ— æ•ˆè¡¨ï¼‰
            tables_to_create = set(health.get('missing_tables', [])) | set(invalid_tables)
            
            # è¡¨å®šä¹‰
            table_definitions = {
                'sync_status': """
                    CREATE TABLE IF NOT EXISTS sync_status (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        table_name TEXT NOT NULL,
                        record_id INTEGER NOT NULL,
                        sync_state TEXT DEFAULT 'pending',
                        local_version INTEGER DEFAULT 1,
                        cloud_version INTEGER DEFAULT 0,
                        last_sync_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(table_name, record_id)
                    )
                """,
                'prisms': """
                    CREATE TABLE IF NOT EXISTS prisms (
                        id TEXT PRIMARY KEY,
                        name TEXT NOT NULL,
                        description TEXT,
                        axis_config TEXT DEFAULT '{}',
                        anchors TEXT DEFAULT '[]',
                        field_data TEXT DEFAULT '[]',
                        version INTEGER DEFAULT 1,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_by TEXT,
                        is_deleted BOOLEAN DEFAULT 0
                    )
                """,
                'prism_versions': """
                    CREATE TABLE IF NOT EXISTS prism_versions (
                        version_id INTEGER PRIMARY KEY AUTOINCREMENT,
                        prism_id TEXT NOT NULL,
                        version INTEGER NOT NULL,
                        snapshot_data TEXT NOT NULL,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        created_by TEXT,
                        change_reason TEXT,
                        FOREIGN KEY (prism_id) REFERENCES prisms (id)
                    )
                """,
                'capsule_types': """
                    CREATE TABLE IF NOT EXISTS capsule_types (
                        id TEXT PRIMARY KEY,
                        name TEXT NOT NULL,
                        name_cn TEXT NOT NULL,
                        description TEXT,
                        icon TEXT,
                        color TEXT NOT NULL,
                        gradient TEXT NOT NULL,
                        examples TEXT,
                        priority_lens TEXT,
                        sort_order INTEGER DEFAULT 0,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """
            }
            
            for table in tables_to_create:
                if table in table_definitions:
                    try:
                        cursor.execute(table_definitions[table])
                        print(f"   âœ“ åˆ›å»ºè¡¨: {table}")
                    except Exception as e:
                        print(f"   âœ— åˆ›å»ºè¡¨ {table} å¤±è´¥: {e}")
            
            # æ’å…¥é»˜è®¤èƒ¶å›Šç±»å‹ï¼ˆå¦‚æœæ˜¯æ–°åˆ›å»ºçš„ï¼‰
            if 'capsule_types' in tables_to_create:
                try:
                    cursor.execute("""
                        INSERT OR IGNORE INTO capsule_types (id, name, name_cn, description, icon, color, gradient, examples, priority_lens, sort_order)
                        VALUES 
                            ('magic', 'MAGIC', 'é­”æ³•', 'ç¥ç§˜ã€æ¢¦å¹»ã€è¶…è‡ªç„¶', 'Sparkles', '#8B5CF6', 'linear-gradient(135deg, #8B5CF6 0%, #3B82F6 100%)', '["ç²’å­åˆæˆ", "è°ƒåˆ¶å™ªå£°", "æ¼”å˜éŸ³è‰²"]', 'texture', 1),
                            ('impact', 'IMPACT', 'æ‰“å‡»', 'å¼ºåŠ›ã€å†²å‡»ã€éœ‡æ’¼', 'Flame', '#EF4444', 'linear-gradient(135deg, #EF4444 0%, #F59E0B 100%)', '["é¼“ç‚¹", "æ‰“å‡»ä¹", "è´æ–¯æ‹¨å¥"]', 'texture', 2),
                            ('atmosphere', 'ATMOSPHERE', 'ç¯å¢ƒ', 'ç©ºé—´ã€æ°›å›´ã€åœºæ™¯', 'Music', '#10B981', 'linear-gradient(135deg, #10B981 0%, #06B6D4 100%)', '["Pad", "æ°›å›´çº¹ç†", "éŸ³æ™¯"]', 'atmosphere', 3)
                    """)
                    print(f"   âœ“ æ’å…¥é»˜è®¤èƒ¶å›Šç±»å‹")
                except Exception as e:
                    print(f"   âœ— æ’å…¥é»˜è®¤èƒ¶å›Šç±»å‹å¤±è´¥: {e}")
            
            # æ’å…¥é»˜è®¤æ£±é•œæ•°æ®ï¼ˆå¦‚æœæ˜¯æ–°åˆ›å»ºçš„ï¼‰
            if 'prisms' in tables_to_create:
                try:
                    default_prisms = [
                        ('texture', 'Texture / Timbre', 'æè¿°å£°éŸ³çš„è´¨æ„Ÿç‰¹å¾', 
                         '{"x_label": {"pos": "Light / å…‰æ˜æ²»æ„ˆ", "neg": "Dark / é»‘æš—ææƒ§"}, "y_label": {"pos": "Playful / è¶£å‘³æ´»è·ƒ", "neg": "Serious / å†™å®ä¸¥è‚ƒ"}}',
                         '[]', '[]', 1),
                        ('source', 'Source & Physics', 'æè¿°å£°éŸ³çš„æ¥æºå’Œç‰©ç†ç‰¹æ€§',
                         '{"x_label": {"pos": "Transient / ç¬æ€å†²å‡»", "neg": "Static / é™æ€é“ºåº•"}, "y_label": {"pos": "Sci-Fi / ç§‘å¹»åˆæˆ", "neg": "Organic / æœ‰æœºè‡ªç„¶"}}',
                         '[]', '[]', 1),
                        ('materiality', 'Materiality / Room', 'æè¿°å£°éŸ³çš„æè´¨å’Œç©ºé—´æ„Ÿ',
                         '{"x_label": {"pos": "Distant / é¥è¿œæ¹¿æ¶¦", "neg": "Close / è´´è€³å¹²æ¶©"}, "y_label": {"pos": "Warm / æš–è½¯å¸éŸ³", "neg": "Cold / å†·ç¡¬åå°„"}}',
                         '[]', '[]', 1),
                        ('temperament', 'Temperament', 'æè¿°å£°éŸ³çš„æƒ…ç»ªå’Œæ€§æ ¼',
                         '{"x_label": {"pos": "Calm / å¹³é™", "neg": "Intense / æ¿€çƒˆ"}, "y_label": {"pos": "Positive / ç§¯æ", "neg": "Negative / æ¶ˆæ"}}',
                         '[]', '[]', 1),
                        ('spectral', 'Spectral', 'æè¿°å£°éŸ³çš„é¢‘è°±ç‰¹å¾',
                         '{"x_label": {"pos": "Bright / æ˜äº®", "neg": "Dark / æš—æ·¡"}, "y_label": {"pos": "Thin / çº¤ç»†", "neg": "Thick / åšé‡"}}',
                         '[]', '[]', 1)
                    ]
                    for prism in default_prisms:
                        cursor.execute("""
                            INSERT OR IGNORE INTO prisms (id, name, description, axis_config, anchors, field_data, version)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                        """, prism)
                    print(f"   âœ“ æ’å…¥é»˜è®¤æ£±é•œæ•°æ® ({len(default_prisms)} ä¸ª)")
                except Exception as e:
                    print(f"   âœ— æ’å…¥é»˜è®¤æ£±é•œæ•°æ®å¤±è´¥: {e}")
            
            # è‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
            if health['missing_fields']:
                # å­—æ®µç±»å‹æ˜ å°„ï¼ˆæ ¹æ®ç”¨é€”æ¨æ–­ï¼‰
                field_types = {
                    'description': 'TEXT',
                    'keywords': 'TEXT',
                    'asset_status': "TEXT DEFAULT 'local'",
                    'cloud_status': "TEXT DEFAULT 'local'",
                    'cloud_id': 'TEXT',
                    'cloud_version': 'INTEGER DEFAULT 1',
                    'files_downloaded': 'BOOLEAN DEFAULT 1',
                    'last_synced_at': 'TIMESTAMP',
                    'local_wav_path': 'TEXT',
                    'local_wav_size': 'INTEGER',
                    'local_wav_hash': 'TEXT',
                    'download_progress': 'INTEGER DEFAULT 0',
                    'download_started_at': 'TIMESTAMP',
                    'preview_downloaded': 'BOOLEAN DEFAULT 0',
                    'asset_last_accessed_at': 'TIMESTAMP',
                    'asset_access_count': 'INTEGER DEFAULT 0',
                    'is_cache_pinned': 'BOOLEAN DEFAULT 0',
                    'audio_uploaded': 'BOOLEAN DEFAULT 0',
                    'owner_supabase_user_id': 'TEXT',
                    'created_by': 'INTEGER',
                }
                
                for field in health['missing_fields']:
                    field_def = field_types.get(field, 'TEXT')
                    try:
                        cursor.execute(f"ALTER TABLE capsules ADD COLUMN {field} {field_def}")
                        print(f"   âœ“ æ·»åŠ å­—æ®µ: {field}")
                    except Exception as e:
                        print(f"   âœ— æ·»åŠ å­—æ®µ {field} å¤±è´¥: {e}")
            
            conn.commit()
            conn.close()
            print("âœ… æ•°æ®åº“ä¿®å¤å®Œæˆï¼")
        else:
            print("âœ… æ•°æ®åº“ schema å®Œæ•´")
        
        # æ£€æŸ¥ prisms è¡¨æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™æ’å…¥é»˜è®¤æ•°æ®
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM prisms")
        prisms_count = cursor.fetchone()[0]
        if prisms_count == 0:
            print("âš ï¸  prisms è¡¨ä¸ºç©ºï¼Œæ’å…¥é»˜è®¤æ£±é•œæ•°æ®...")
            default_prisms = [
                ('texture', 'Texture / Timbre', 'æè¿°å£°éŸ³çš„è´¨æ„Ÿç‰¹å¾', 
                 '{"x_label": {"pos": "Light / å…‰æ˜æ²»æ„ˆ", "neg": "Dark / é»‘æš—ææƒ§"}, "y_label": {"pos": "Playful / è¶£å‘³æ´»è·ƒ", "neg": "Serious / å†™å®ä¸¥è‚ƒ"}}',
                 '[]', '[]', 1),
                ('source', 'Source & Physics', 'æè¿°å£°éŸ³çš„æ¥æºå’Œç‰©ç†ç‰¹æ€§',
                 '{"x_label": {"pos": "Transient / ç¬æ€å†²å‡»", "neg": "Static / é™æ€é“ºåº•"}, "y_label": {"pos": "Sci-Fi / ç§‘å¹»åˆæˆ", "neg": "Organic / æœ‰æœºè‡ªç„¶"}}',
                 '[]', '[]', 1),
                ('materiality', 'Materiality / Room', 'æè¿°å£°éŸ³çš„æè´¨å’Œç©ºé—´æ„Ÿ',
                 '{"x_label": {"pos": "Distant / é¥è¿œæ¹¿æ¶¦", "neg": "Close / è´´è€³å¹²æ¶©"}, "y_label": {"pos": "Warm / æš–è½¯å¸éŸ³", "neg": "Cold / å†·ç¡¬åå°„"}}',
                 '[]', '[]', 1),
                ('temperament', 'Temperament', 'æè¿°å£°éŸ³çš„æƒ…ç»ªå’Œæ€§æ ¼',
                 '{"x_label": {"pos": "Calm / å¹³é™", "neg": "Intense / æ¿€çƒˆ"}, "y_label": {"pos": "Positive / ç§¯æ", "neg": "Negative / æ¶ˆæ"}}',
                 '[]', '[]', 1),
                ('spectral', 'Spectral', 'æè¿°å£°éŸ³çš„é¢‘è°±ç‰¹å¾',
                 '{"x_label": {"pos": "Bright / æ˜äº®", "neg": "Dark / æš—æ·¡"}, "y_label": {"pos": "Thin / çº¤ç»†", "neg": "Thick / åšé‡"}}',
                 '[]', '[]', 1)
            ]
            for prism in default_prisms:
                cursor.execute("""
                    INSERT OR IGNORE INTO prisms (id, name, description, axis_config, anchors, field_data, version)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, prism)
            conn.commit()
            print(f"   âœ“ å·²æ’å…¥ {len(default_prisms)} ä¸ªé»˜è®¤æ£±é•œ")
        conn.close()

    # å¯åŠ¨æœåŠ¡å™¨ï¼ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä¸­çš„ç«¯å£ï¼‰
    port = ARGS.port
    host = os.getenv('API_HOST', 'localhost')

    print(f"\n{'='*60}")
    print(f"ğŸš€ Synesth èƒ¶å›Š API æœåŠ¡å™¨")
    print(f"{'='*60}")
    print(f"ç›‘å¬åœ°å€: http://{host}:{port}")
    print(f"æ•°æ®åº“: {db_path}")
    print(f"å¯¼å‡ºç›®å½•: {EXPORT_DIR}")
    print(f"èµ„æºç›®å½•: {RESOURCE_DIR}")
    print(f"{'='*60}\n")

    app.run(host=host, port=port, debug=False)
