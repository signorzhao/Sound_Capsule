"""
Flask Blueprint for Sync Routes

This module contains all synchronization-related routes for the Sound Capsule API.
Migrated from capsule_api.py as part of the API modularization effort (Phase G).

Routes:
- GET  /api/sync/status - Get sync status overview
- GET  /api/sync/pending - Get pending sync records
- POST /api/sync/mark-pending - Mark record for sync
- POST /api/sync/upload - Upload data to cloud
- GET  /api/sync/download - Download data from cloud
- GET  /api/sync/conflicts - Get unresolved conflicts
- POST /api/sync/resolve-conflict - Resolve a conflict
- POST /api/sync/lightweight - Lightweight metadata sync
"""

import sqlite3
import os
import logging
from flask import Blueprint, request, jsonify
from functools import wraps

# Import dependencies from parent modules
from pathlib import Path

# Note: token_required and APIError are defined in common module
from sync_service import get_sync_service
from capsule_db import get_database
from auth import get_auth_manager
from common import APIError, PathManager

logger = logging.getLogger(__name__)

# Define Blueprint
sync_bp = Blueprint('sync_bp', __name__)


# ============================================
# Error Handling & Auth
# ============================================


def get_current_user():
    """
    ä»è¯·æ±‚ä¸­è·å–å½“å‰ç”¨æˆ·

    Returns:
        ç”¨æˆ·ä¿¡æ¯å­—å…¸æˆ– None

    Raises:
        APIError: å¦‚æœè®¤è¯å¤±è´¥
    """
    auth_header = request.headers.get('Authorization')

    if not auth_header:
        return None  # æœªæä¾› Tokenï¼Œè¿”å› Noneï¼ˆå…è®¸åŒ¿åè®¿é—®ï¼‰

    try:
        # è§£æ Bearer token
        token = auth_header.split(' ')[1]
    except IndexError:
        raise APIError('Token æ ¼å¼é”™è¯¯', 401)

    # éªŒè¯ token
    auth_manager = get_auth_manager()
    payload = auth_manager.verify_access_token(token)

    if not payload:
        raise APIError('Token æ— æ•ˆæˆ–å·²è¿‡æœŸ', 401)

    # è·å–ç”¨æˆ·ä¿¡æ¯
    user = auth_manager.get_user_by_id(payload['user_id'])

    if not user:
        raise APIError('ç”¨æˆ·ä¸å­˜åœ¨', 401)

    return user


def token_required(f):
    """
    Token è®¤è¯è£…é¥°å™¨

    ç”¨äºä¿æŠ¤éœ€è¦è®¤è¯çš„ç«¯ç‚¹
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        # å…è®¸ OPTIONS é¢„æ£€è¯·æ±‚é€šè¿‡ï¼ˆCORSï¼‰
        if request.method == 'OPTIONS':
            return jsonify({'success': True}), 200

        user = get_current_user()

        if not user:
            raise APIError('éœ€è¦è®¤è¯', 401)

        # å°†ç”¨æˆ·ä¿¡æ¯ä¼ é€’ç»™è§†å›¾å‡½æ•°
        return f(current_user=user, *args, **kwargs)

    # ä¿ç•™åŸå§‹å‡½æ•°çš„åç§°
    decorated.__name__ = f.__name__
    return decorated


# ============================================================
# Sync Status Routes
# ============================================================

@sync_bp.route('/status', methods=['GET'])
def get_sync_status_endpoint():
    """
    è·å–åŒæ­¥çŠ¶æ€æ¦‚è§ˆ

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "synced_count": 10,
                "pending_count": 3,
                "conflict_count": 0,
                "last_sync_at": "2026-01-10T10:00:00Z"
            }
        }
    """
    try:
        sync_service = get_sync_service()
        status = sync_service.get_sync_status()

        return jsonify({
            'success': True,
            'data': status
        })

    except Exception as e:
        raise APIError(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}", 500)


@sync_bp.route('/pending', methods=['GET'])
def get_pending_records():
    """
    è·å–å¾…åŒæ­¥çš„è®°å½•

    Query Parameters:
        - table: è¡¨åï¼ˆå¯é€‰ï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "records": [...]
            }
        }
    """
    try:
        table_name = request.args.get('table')

        sync_service = get_sync_service()
        records = sync_service.get_pending_records(table_name)

        return jsonify({
            'success': True,
            'data': {
                'records': records,
                'count': len(records)
            }
        })

    except Exception as e:
        raise APIError(f"è·å–å¾…åŒæ­¥è®°å½•å¤±è´¥: {e}", 500)


@sync_bp.route('/mark-pending', methods=['POST'])
@token_required
def mark_record_for_sync(current_user):
    """
    æ ‡è®°è®°å½•ä¸ºå¾…åŒæ­¥

    è¯·æ±‚ä½“:
        {
            "table": "capsules",
            "record_id": 123,
            "operation": "update"
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "å·²æ ‡è®°ä¸ºå¾…åŒæ­¥"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        # å…¼å®¹ä¸¤ç§å‚æ•°æ ¼å¼
        table_name = data.get('table') or data.get('table_name')
        record_id = data.get('record_id') or data.get('record_id')
        operation = data.get('operation', 'update')

        if not all([table_name, record_id]):
            raise APIError('ç¼ºå°‘å¿…è¦å‚æ•°: table, record_id', 400)

        sync_service = get_sync_service()
        success = sync_service.mark_for_sync(table_name, record_id, operation)

        if success:
            return jsonify({
                'success': True,
                'message': 'å·²æ ‡è®°ä¸ºå¾…åŒæ­¥'
            })
        else:
            raise APIError('æ ‡è®°å¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"æ ‡è®°å¾…åŒæ­¥å¤±è´¥: {e}", 500)


# ============================================================
# Cloud Sync Routes
# ============================================================

@sync_bp.route('/upload', methods=['POST'])
@token_required
def upload_to_cloud(current_user):
    """
    ä¸Šä¼ æ•°æ®åˆ°äº‘ç«¯

    è¯·æ±‚ä½“:
        {
            "table": "capsules",
            "records": [...]
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "uploaded": 5,
                "failed": 0
            }
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        table_name = data.get('table')
        records = data.get('records', [])

        if not table_name:
            raise APIError('ç¼ºå°‘è¡¨å', 400)

        # è°ƒè¯•æ—¥å¿—
        logger.info(f"\n{'='*60}")
        logger.info(f"[SYNC] å¼€å§‹ä¸Šä¼ åˆ°äº‘ç«¯")
        logger.info(f"[SYNC] è¡¨å: {table_name}")
        logger.info(f"[SYNC] è®°å½•æ•°: {len(records)}")
        logger.info(f"[SYNC] å®Œæ•´è¯·æ±‚ä½“: {data}")
        if records:
            logger.info(f"[SYNC] ç¬¬ä¸€æ¡è®°å½•: {records[0]}")
        logger.info(f"{'='*60}\n")

        # çœŸå®çš„äº‘ç«¯ä¸Šä¼ é€»è¾‘
        try:
            from supabase_client import get_supabase_client
            from common import load_user_config  # Import helper function

            supabase = get_supabase_client()
            if not supabase:
                raise Exception("Supabase å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

            # è·å–ç”¨æˆ· IDï¼ˆä¼˜å…ˆä½¿ç”¨ supabase_user_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœ¬åœ° IDï¼‰
            user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

            uploaded = 0
            failed = 0
            cloud_id_mapping = {}  # æœ¬åœ° ID -> äº‘ç«¯ ID æ˜ å°„

            # æ ¹æ®ä¸åŒçš„è¡¨åå¤„ç†
            if table_name == 'capsules':
                # è·å–æœ¬åœ°æ•°æ®åº“è¿æ¥
                db = get_database()
                db.connect()
                cursor = db.conn.cursor()

                try:
                    # ä¸Šä¼ èƒ¶å›Šæ•°æ®
                    for idx, pending_record in enumerate(records, 1):
                        logger.info(f"\n[SYNC] å¤„ç†ç¬¬ {idx}/{len(records)} æ¡è®°å½•...")
                        try:
                            # ä» pending_record ä¸­è·å–å®é™…çš„ record_id
                            record_id = pending_record.get('record_id')
                            logger.info(f"[SYNC]   record_id: {record_id}")

                            # ä»æ•°æ®åº“è·å–å®Œæ•´çš„èƒ¶å›Šæ•°æ®
                            cursor.execute("SELECT * FROM capsules WHERE id = ?", (record_id,))
                            row = cursor.fetchone()

                            if not row:
                                logger.warning(f"[SYNC]   âœ— è­¦å‘Š: èƒ¶å›Š ID {record_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                                failed += 1
                                continue

                            # å°†è¡Œæ•°æ®è½¬æ¢ä¸ºå­—å…¸
                            columns = [desc[0] for desc in cursor.description]
                            capsule_data = dict(zip(columns, row))

                            # è·å–æŠ€æœ¯å…ƒæ•°æ®
                            cursor.execute("""SELECT bpm, duration, sample_rate, plugin_count, plugin_list,
                                                   has_sends, has_folder_bus, tracks_included
                                            FROM capsule_metadata WHERE capsule_id = ?""", (record_id,))
                            metadata_row = cursor.fetchone()
                            if metadata_row:
                                capsule_data['bpm'] = metadata_row[0]
                                capsule_data['duration'] = metadata_row[1]
                                capsule_data['sample_rate'] = metadata_row[2]
                                capsule_data['plugin_count'] = metadata_row[3]
                                capsule_data['plugin_list'] = metadata_row[4]
                                capsule_data['has_sends'] = metadata_row[5]
                                capsule_data['has_folder_bus'] = metadata_row[6]
                                capsule_data['tracks_included'] = metadata_row[7]

                            logger.info(f"[SYNC]   âœ“ èƒ¶å›Šåç§°: {capsule_data.get('name')}")

                            # ä¸Šä¼ åˆ°äº‘ç«¯ï¼ˆä»… keywords æ›´æ–°ï¼‰
                            logger.info(f"[SYNC]   â†’ æ­£åœ¨ä¸Šä¼ åˆ° Supabase...")
                            existing_cloud = supabase.get_cloud_capsule_by_local_id(user_id, record_id)
                            result = None
                            if existing_cloud:
                                remote_meta = existing_cloud.get('metadata') or {}
                                remote_keywords = remote_meta.get('keywords') if isinstance(remote_meta, dict) else None
                                local_keywords = capsule_data.get('keywords')
                                if local_keywords != remote_keywords:
                                    result = supabase.update_capsule_keywords(user_id, record_id, local_keywords)
                                else:
                                    result = existing_cloud
                            else:
                                result = supabase.upload_capsule(user_id, capsule_data)

                            if result:
                                uploaded += 1
                                cloud_id = result.get('id')
                                cloud_id_mapping[record_id] = cloud_id
                                logger.info(f"[SYNC]   âœ“ ä¸Šä¼ æˆåŠŸ!")
                                logger.info(f"[SYNC]     - æœ¬åœ°ID: {record_id}")
                                logger.info(f"[SYNC]     - äº‘ç«¯ID: {cloud_id}")
                                logger.info(f"[SYNC]     - ç‰ˆæœ¬: {result.get('version')}")
                                
                                # ğŸ”§ ç«‹å³æ›´æ–° cloud_idï¼ˆé˜²æ­¢åç»­æ–‡ä»¶ä¸Šä¼ å¤±è´¥å¯¼è‡´æ•°æ®ä¸ä¸€è‡´ï¼‰
                                cursor.execute("""
                                    UPDATE capsules
                                    SET cloud_id = ?,
                                        cloud_version = ?
                                    WHERE id = ?
                                """, (cloud_id, result.get('version', 1), record_id))
                                db.conn.commit()
                                logger.info(f"[SYNC]   âœ“ å·²è®¾ç½® cloud_id")

                                # ğŸ¯ ä¸Šä¼  Audio æ–‡ä»¶å¤¹ï¼ˆä»…ç¼ºå¤±éƒ¨åˆ†ï¼‰
                                import os
                                capsule_dir = capsule_data.get('file_path', '')
                                if capsule_dir:
                                    from pathlib import Path
                                    import glob

                                    # ä»è·¯å¾„ç®¡ç†å™¨è·å–å¯¼å‡ºç›®å½•
                                    pm = PathManager.get_instance()
                                    full_capsule_dir = pm.export_dir / capsule_dir
                                    
                                    logger.info(f"[SYNC] ğŸ” æŸ¥æ‰¾èƒ¶å›Šç›®å½•: {full_capsule_dir}")
                                    
                                    if not full_capsule_dir.exists():
                                        logger.warning(f"[SYNC] âš  èƒ¶å›Šç›®å½•ä¸å­˜åœ¨: {full_capsule_dir}")
                                        full_capsule_dir = None

                                    if full_capsule_dir:
                                        # ğŸµ ä¸Šä¼ é¢„è§ˆéŸ³é¢‘æ–‡ä»¶ï¼ˆä»…ç¼ºå¤±ï¼‰
                                        preview_audio = capsule_data.get('preview_audio')
                                        if preview_audio:
                                            preview_path = full_capsule_dir / preview_audio
                                            if preview_path.exists():
                                                if supabase.storage_file_exists(user_id, capsule_dir, preview_audio):
                                                    logger.info(f"[SYNC]   âœ“ é¢„è§ˆéŸ³é¢‘å·²å­˜åœ¨ï¼Œè·³è¿‡")
                                                else:
                                                    logger.info(f"[SYNC] â†’ ä¸Šä¼ é¢„è§ˆéŸ³é¢‘: {preview_audio}")
                                                    preview_result = supabase.upload_file(
                                                        user_id=user_id,
                                                        capsule_folder_name=capsule_dir,
                                                        file_type='preview',
                                                        file_path=str(preview_path)
                                                    )
                                                    if preview_result:
                                                        logger.info(f"[SYNC]   âœ“ é¢„è§ˆéŸ³é¢‘ä¸Šä¼ æˆåŠŸ")
                                                        logger.info(f"[SYNC]     - å¤§å°: {preview_result.get('size', 0):,} bytes")
                                                        logger.info(f"[SYNC]     - è·¯å¾„: {preview_result.get('storage_path', 'N/A')}")
                                                    else:
                                                        logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘ä¸Šä¼ å¤±è´¥")
                                            else:
                                                logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {preview_path}")

                                        # ğŸ“„ ä¸Šä¼  RPP é¡¹ç›®æ–‡ä»¶ï¼ˆä»…ç¼ºå¤±ï¼‰
                                        rpp_file = capsule_data.get('rpp_file')
                                        if rpp_file:
                                            rpp_path = full_capsule_dir / rpp_file
                                            if rpp_path.exists():
                                                if supabase.storage_file_exists(user_id, capsule_dir, rpp_file):
                                                    logger.info(f"[SYNC]   âœ“ RPP å·²å­˜åœ¨ï¼Œè·³è¿‡")
                                                else:
                                                    logger.info(f"[SYNC] â†’ ä¸Šä¼  RPP æ–‡ä»¶: {rpp_file}")
                                                    rpp_result = supabase.upload_file(
                                                        user_id=user_id,
                                                        capsule_folder_name=capsule_dir,
                                                        file_type='rpp',
                                                        file_path=str(rpp_path)
                                                    )
                                                    if rpp_result:
                                                        logger.info(f"[SYNC]   âœ“ RPP æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                                                        logger.info(f"[SYNC]     - å¤§å°: {rpp_result.get('size', 0):,} bytes")
                                                        logger.info(f"[SYNC]     - è·¯å¾„: {rpp_result.get('storage_path', 'N/A')}")
                                                    else:
                                                        logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
                                            else:
                                                logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸å­˜åœ¨: {rpp_path}")

                                        # ğŸ“‹ ä¸Šä¼  metadata.json æ–‡ä»¶ï¼ˆä»…ç¼ºå¤±ï¼‰
                                        metadata_file = full_capsule_dir / "metadata.json"
                                        if metadata_file.exists():
                                            if supabase.storage_file_exists(user_id, capsule_dir, "metadata.json"):
                                                logger.info(f"[SYNC]   âœ“ metadata.json å·²å­˜åœ¨ï¼Œè·³è¿‡")
                                            else:
                                                logger.info(f"[SYNC] â†’ ä¸Šä¼  metadata.json...")
                                                metadata_result = supabase.upload_file(
                                                    user_id=user_id,
                                                    capsule_folder_name=capsule_dir,
                                                    file_type='metadata',
                                                    file_path=str(metadata_file)
                                                )
                                                if metadata_result:
                                                    logger.info(f"[SYNC]   âœ“ metadata.json ä¸Šä¼ æˆåŠŸ")
                                                    logger.info(f"[SYNC]     - å¤§å°: {metadata_result.get('size', 0):,} bytes")
                                                    logger.info(f"[SYNC]     - è·¯å¾„: {metadata_result.get('storage_path', 'N/A')}")
                                                else:
                                                    logger.warning(f"[SYNC]   âš  metadata.json ä¸Šä¼ å¤±è´¥")
                                        else:
                                            logger.warning(f"[SYNC]   âš  metadata.json æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")

                                        # ğŸ§ ä¸Šä¼  Audio æ–‡ä»¶å¤¹ï¼ˆä»…ç¼ºå¤±ï¼‰
                                        audio_folder = full_capsule_dir / "Audio"
                                        if audio_folder.exists():
                                            local_files = [
                                                entry for entry in audio_folder.iterdir()
                                                if entry.is_file() and not entry.name.startswith('.')
                                                and entry.suffix.lower() in ['.wav', '.mp3', '.ogg', '.flac', '.aiff']
                                            ]
                                            remote_files = set(supabase.list_audio_files(user_id, capsule_dir))
                                            missing_files = [f for f in local_files if f.name not in remote_files]
                                            if not missing_files:
                                                logger.info(f"[SYNC]   âœ“ Audio å·²å®Œæ•´å­˜åœ¨ï¼Œè·³è¿‡")
                                            else:
                                                logger.info(f"[SYNC] â†’ ä¸Šä¼  Audio æ–‡ä»¶å¤¹ï¼ˆç¼ºå¤± {len(missing_files)} ä¸ªï¼‰...")
                                                audio_result = supabase.upload_audio_files(
                                                    user_id=user_id,
                                                    capsule_folder_name=capsule_dir,
                                                    audio_files=missing_files
                                                )
                                                if audio_result and audio_result.get('success', False):
                                                    logger.info(f"[SYNC]   âœ“ Audio æ–‡ä»¶å¤¹ä¸Šä¼ æˆåŠŸ")
                                                    logger.info(f"[SYNC]     - æ–‡ä»¶æ•°: {audio_result.get('files_uploaded', 0)}")
                                                    logger.info(f"[SYNC]     - æ€»å¤§å°: {audio_result.get('total_size', 0):,} bytes ({audio_result.get('total_size', 0) / 1024 / 1024:.2f} MB)")
                                                    if audio_result.get('errors'):
                                                        logger.warning(f"[SYNC]     - å¤±è´¥: {len(audio_result.get('errors', []))} ä¸ªæ–‡ä»¶")
                                                else:
                                                    logger.warning(f"[SYNC]   âš  Audio æ–‡ä»¶å¤¹ä¸Šä¼ å¤±è´¥")
                                        else:
                                            logger.info(f"[SYNC]   â„¹ æ—  Audio æ–‡ä»¶å¤¹ï¼Œè·³è¿‡")
                                    else:
                                        logger.warning(f"[SYNC] âš  æ— æ³•æ‰¾åˆ°èƒ¶å›Šç›®å½•: {capsule_dir}")

                                # æ›´æ–°æœ¬åœ°æ•°æ®åº“çš„äº‘åŒæ­¥çŠ¶æ€ï¼ˆcloud_id å·²åœ¨ä¸Šä¼ æˆåŠŸåç«‹å³è®¾ç½®ï¼‰
                                cursor.execute("""
                                    UPDATE capsules
                                    SET cloud_status = 'synced',
                                        last_synced_at = CURRENT_TIMESTAMP
                                    WHERE id = ?
                                """, (record_id,))
                                db.conn.commit()
                                logger.info(f"[SYNC]   âœ“ å·²æ›´æ–°æœ¬åœ°åŒæ­¥çŠ¶æ€ä¸º 'synced'")
                            else:
                                failed += 1
                                logger.error(f"[SYNC]   âœ— ä¸Šä¼ å¤±è´¥: result is None")
                        except Exception as e:
                            failed += 1
                            logger.error(f"[SYNC]   âœ— å¼‚å¸¸: {e}")
                            import traceback
                            logger.error(traceback.format_exc())

                    # ä¸Šä¼ èƒ¶å›Šçš„æ ‡ç­¾å’Œåæ ‡ï¼ˆä½¿ç”¨å·²æœ‰çš„ db å’Œ cursorï¼‰
                    if cloud_id_mapping:
                        logger.info(f"[SYNC] ğŸ“ å‡†å¤‡ä¸Šä¼ æ ‡ç­¾ï¼Œcloud_id_mapping: {cloud_id_mapping}")
                        for local_id, cloud_id in cloud_id_mapping.items():
                            # ä¸Šä¼ æ ‡ç­¾
                            cursor.execute("SELECT * FROM capsule_tags WHERE capsule_id = ?", (local_id,))
                            tags = []
                            for row in cursor.fetchall():
                                tags.append({
                                    'lens': row[2],         # ä½¿ç”¨ç»Ÿä¸€çš„ lens å‘½å
                                    'word_id': row[3],      # word_id
                                    'word_cn': row[4],      # word_cn
                                    'word_en': row[5],      # word_en
                                    'x': row[6],            # x
                                    'y': row[7],            # y
                                })
                            logger.info(f"[SYNC] ğŸ“ æœ¬åœ°èƒ¶å›Š {local_id} æœ‰ {len(tags)} ä¸ªæ ‡ç­¾")
                            if tags:
                                logger.info(f"[SYNC] â†’ ä¸Šä¼ æ ‡ç­¾åˆ°äº‘ç«¯ (capsule_id={cloud_id})...")
                                supabase.upload_tags(user_id, cloud_id, tags)
                            else:
                                logger.warning(f"[SYNC] âš  æœ¬åœ°èƒ¶å›Š {local_id} æ²¡æœ‰æ ‡ç­¾")

                            # ä¸Šä¼ åæ ‡
                            cursor.execute("SELECT * FROM capsule_coordinates WHERE capsule_id = ?", (local_id,))
                            coords = []
                            for row in cursor.fetchall():
                                coords.append({
                                    'lens': row[2],
                                    'dimension': row[3],
                                    'value': row[4],
                                })
                            if coords:
                                supabase.upload_coordinates(user_id, cloud_id, coords)
                finally:
                    # ç¡®ä¿å…³é—­æ•°æ®åº“è¿æ¥
                    db.close()

            elif table_name == 'capsule_tags':
                # æ ‡ç­¾ä¼šéšç€èƒ¶å›Šä¸€èµ·ä¸Šä¼ 
                uploaded = len(records)
            elif table_name == 'capsule_coordinates':
                # åæ ‡ä¼šéšç€èƒ¶å›Šä¸€èµ·ä¸Šä¼ 
                uploaded = len(records)
            else:
                raise Exception(f"ä¸æ”¯æŒçš„è¡¨å: {table_name}")

            # æ ‡è®°ä¸ºå·²åŒæ­¥ï¼ˆåªæ ‡è®°æˆåŠŸä¸Šä¼ çš„è®°å½•ï¼‰
            sync_service = get_sync_service()
            synced_count = 0

            for pending_record in records:
                record_id = pending_record.get('record_id')
                if record_id and record_id in cloud_id_mapping:
                    # åªæœ‰æˆåŠŸä¸Šä¼ åˆ°äº‘ç«¯çš„è®°å½•æ‰æ ‡è®°ä¸ºå·²åŒæ­¥
                    sync_service.mark_as_synced(table_name, record_id, 1)
                    synced_count += 1
                    logger.info(f"[SYNC] æ ‡è®°ä¸ºå·²åŒæ­¥: {table_name} ID {record_id}")

            logger.info(f"[SYNC] åŒæ­¥å®Œæˆ: æˆåŠŸ {uploaded}, å¤±è´¥ {failed}, æ ‡è®° {synced_count}")

            return jsonify({
                'success': True,
                'data': {
                    'uploaded': uploaded,
                    'failed': failed
                }
            })

        except ImportError:
            raise Exception("Supabase SDK æœªå®‰è£…")
        except Exception as e:
            raise Exception(f"äº‘ç«¯ä¸Šä¼ å¤±è´¥: {str(e)}")

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"ä¸Šä¼ åˆ°äº‘ç«¯å¤±è´¥: {e}", 500)


@sync_bp.route('/download', methods=['GET'])
@token_required
def download_from_cloud(current_user):
    """
    ä»äº‘ç«¯ä¸‹è½½æ•°æ®

    Query Parameters:
        - table: è¡¨å
        - since: ISO 8601 æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "records": [...],
                "deleted_ids": [...]
            }
        }
    """
    try:
        table_name = request.args.get('table')
        since = request.args.get('since')

        if not table_name:
            raise APIError('ç¼ºå°‘è¡¨å', 400)

        # çœŸå®çš„äº‘ç«¯ä¸‹è½½é€»è¾‘
        try:
            from supabase_client import get_supabase_client
            from common import load_user_config  # Import helper function

            supabase = get_supabase_client()
            if not supabase:
                raise Exception("Supabase å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

            # è·å–ç”¨æˆ· IDï¼ˆä¼˜å…ˆä½¿ç”¨ supabase_user_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœ¬åœ° IDï¼‰
            user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

            # æ ¹æ® table_name ä¸‹è½½å¯¹åº”çš„æ•°æ®
            if table_name == 'capsules':
                records = supabase.download_capsules(user_id)

                # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
                if records:
                    db = get_database()
                    db.connect()
                    try:
                        for record in records:
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæŒ‰ cloud_id / uuid / name+file_pathï¼‰
                            cursor = db.conn.cursor()
                            cursor.execute("SELECT id FROM capsules WHERE cloud_id = ?", (record.get('id'),))
                            existing = cursor.fetchone()
                            if not existing:
                                cursor.execute("SELECT id FROM capsules WHERE uuid = ?", (record.get('id'),))
                                existing = cursor.fetchone()

                            # å‡†å¤‡æœ¬åœ°æ•°æ®
                            capsule_folder_name = (record.get('metadata') or {}).get('file_path') or record.get('name', '')

                            local_data = {
                                'uuid': record.get('id'),
                                'name': record.get('name'),
                                'file_path': capsule_folder_name,
                                'preview_audio': record.get('metadata', {}).get('preview_audio'),
                                'rpp_file': record.get('metadata', {}).get('rpp_file'),
                                'capsule_type': record.get('metadata', {}).get('capsule_type', 'magic'),
                                'cloud_status': 'synced',
                                'cloud_id': record.get('id'),
                                'cloud_version': record.get('version', 1),
                            }

                            if existing:
                                # æ›´æ–°ç°æœ‰è®°å½•
                                cursor.execute("""
                                    UPDATE capsules
                                    SET name = ?, file_path = ?, preview_audio = ?, rpp_file = ?,
                                        capsule_type = ?, cloud_status = ?, cloud_id = ?, cloud_version = ?,
                                        last_synced_at = CURRENT_TIMESTAMP
                                    WHERE id = ?
                                """, (
                                    local_data['name'], local_data['file_path'], local_data['preview_audio'],
                                    local_data['rpp_file'], local_data['capsule_type'], local_data['cloud_status'],
                                    local_data['cloud_id'], local_data['cloud_version'], existing[0]
                                ))
                            else:
                                # å…œåº•å†æŒ‰ name + file_path åŒ¹é…ï¼Œé¿å… UUID å†²çª
                                cursor.execute("""
                                    SELECT id FROM capsules
                                    WHERE name = ? AND file_path = ?
                                """, (local_data['name'], local_data['file_path']))
                                existing_by_name = cursor.fetchone()
                                if existing_by_name:
                                    cursor.execute("""
                                        UPDATE capsules
                                        SET preview_audio = ?, rpp_file = ?,
                                            capsule_type = ?, cloud_status = ?, cloud_id = ?, cloud_version = ?,
                                            last_synced_at = CURRENT_TIMESTAMP
                                        WHERE id = ?
                                    """, (
                                        local_data['preview_audio'], local_data['rpp_file'], local_data['capsule_type'],
                                        local_data['cloud_status'], local_data['cloud_id'], local_data['cloud_version'],
                                        existing_by_name[0]
                                    ))
                                    continue
                                # æ’å…¥æ–°è®°å½•
                                cursor.execute("""
                                    INSERT INTO capsules (uuid, name, file_path, preview_audio, rpp_file,
                                                         capsule_type, cloud_status, cloud_id, cloud_version)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                                """, (
                                    local_data['uuid'], local_data['name'], local_data['file_path'],
                                    local_data['preview_audio'], local_data['rpp_file'], local_data['capsule_type'],
                                    local_data['cloud_status'], local_data['cloud_id'], local_data['cloud_version']
                                ))

                                # è·å–æ–°æ’å…¥çš„èƒ¶å›ŠID
                                capsule_id = cursor.lastrowid

                                # ä»äº‘ç«¯ metadata æ¢å¤æŠ€æœ¯å…ƒæ•°æ®
                                metadata = record.get('metadata', {})
                                if metadata.get('bpm') or metadata.get('plugin_count'):
                                    cursor.execute("""
                                        INSERT INTO capsule_metadata
                                        (capsule_id, bpm, duration, sample_rate, plugin_count, plugin_list,
                                         has_sends, has_folder_bus, tracks_included)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        capsule_id,
                                        metadata.get('bpm'),
                                        metadata.get('duration'),
                                        metadata.get('sample_rate'),
                                        metadata.get('plugin_count'),
                                        metadata.get('plugin_list'),
                                        metadata.get('has_sends'),
                                        metadata.get('has_folder_bus'),
                                        metadata.get('tracks_included')
                                    ))

                                # ä»äº‘ç«¯è·å–å¹¶æ¢å¤æ ‡ç­¾
                                cloud_tags = supabase.download_capsule_tags(record.get('id'))
                                if cloud_tags:
                                    for tag in cloud_tags:
                                        cursor.execute("""
                                            INSERT INTO capsule_tags
                                            (capsule_id, lens, word_id, word_cn, word_en, x, y)
                                            VALUES (?, ?, ?, ?, ?, ?, ?)
                                        """, (
                                            capsule_id,
                                            tag.get('lens') or tag.get('lens_id'),
                                            tag.get('word_id'),
                                            tag.get('word_cn'),
                                            tag.get('word_en'),
                                            tag.get('x'),
                                            tag.get('y')
                                        ))

                                # ä»äº‘ç«¯è·å–å¹¶æ¢å¤åæ ‡
                                try:
                                    cloud_coords_res = supabase.client.table('cloud_capsule_coordinates').select('*').eq('capsule_id', record.get('id')).execute()
                                    if cloud_coords_res.data:
                                        for coord in cloud_coords_res.data:
                                            cursor.execute("""
                                                INSERT INTO capsule_coordinates
                                                (capsule_id, lens, dimension, value)
                                                VALUES (?, ?, ?, ?)
                                            """, (
                                                capsule_id,
                                                coord.get('lens') or coord.get('lens_id'),
                                                coord.get('dimension'),
                                                coord.get('value')
                                            ))
                                except Exception as e:
                                    logger.warning(f"æ¢å¤åæ ‡å¤±è´¥ (èƒ¶å›Š {capsule_id}): {e}")

                                # åˆ›å»ºåŒæ­¥çŠ¶æ€è®°å½•
                                cursor.execute("""
                                    INSERT OR REPLACE INTO sync_status
                                    (table_name, record_id, sync_state, local_version, cloud_version, created_at, updated_at)
                                    VALUES ('capsules', ?, 'synced', ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                                """, (capsule_id, record.get('version', 1), record.get('version', 1)))

                                # ğŸ“¥ ä¸‹è½½æ–‡ä»¶ï¼ˆåªå¯¹æ–°ä¸‹è½½çš„èƒ¶å›Šï¼‰
                                try:
                                    from pathlib import Path
                                    import os

                                    # ç¡®å®šå¯¼å‡ºç›®å½• - ä» PathManager è·å–
                                    from common import PathManager
                                    pm = PathManager.get_instance()
                                    export_dir = pm.export_dir
                                    capsule_dir = Path(export_dir) / local_data['file_path']
                                    capsule_dir.mkdir(parents=True, exist_ok=True)

                                    logger.info(f"[SYNC] ğŸ“¥ å¼€å§‹ä¸‹è½½èƒ¶å›Šæ–‡ä»¶: {local_data['name']}")

                                    # ä½¿ç”¨äº‘ç«¯è®°å½•ä¸­çš„åŸä½œè€… user_id
                                    owner_id = record.get('user_id')
                                    if not owner_id:
                                        owner_id = user_id

                                    # 1. ä¸‹è½½é¢„è§ˆéŸ³é¢‘
                                    if local_data['preview_audio']:
                                        preview_path = capsule_dir / local_data['preview_audio']
                                        logger.info(f"[SYNC]   â†’ ä¸‹è½½é¢„è§ˆéŸ³é¢‘: {local_data['preview_audio']}")
                                        logger.info(f"[SYNC]     æ–‡ä»¶å¤¹: {local_data['file_path']}, ä½œè€…: {owner_id}, è·¯å¾„: {owner_id}/{local_data['file_path']}/preview")
                                        if supabase.download_file(owner_id, local_data['file_path'], 'preview', str(preview_path)):
                                            logger.info(f"[SYNC]   âœ“ é¢„è§ˆéŸ³é¢‘ä¸‹è½½æˆåŠŸ")
                                        else:
                                            logger.warning(f"[SYNC]   âš  é¢„è§ˆéŸ³é¢‘ä¸‹è½½å¤±è´¥")

                                    # 2. ä¸‹è½½ RPP æ–‡ä»¶
                                    if local_data['rpp_file']:
                                        rpp_path = capsule_dir / local_data['rpp_file']
                                        logger.info(f"[SYNC]   â†’ ä¸‹è½½ RPP æ–‡ä»¶: {local_data['rpp_file']}")
                                        logger.info(f"[SYNC]     æ–‡ä»¶å¤¹: {local_data['file_path']}, ä½œè€…: {owner_id}, è·¯å¾„: {owner_id}/{local_data['file_path']}/project.rpp")
                                        if supabase.download_file(owner_id, local_data['file_path'], 'rpp', str(rpp_path)):
                                            logger.info(f"[SYNC]   âœ“ RPP æ–‡ä»¶ä¸‹è½½æˆåŠŸ")
                                        else:
                                            logger.warning(f"[SYNC]   âš  RPP æ–‡ä»¶ä¸‹è½½å¤±è´¥")

                                    logger.info(f"[SYNC] âœ“ èƒ¶å›Šæ–‡ä»¶ä¸‹è½½å®Œæˆ: {local_data['name']}")

                                except Exception as e:
                                    logger.error(f"[SYNC] âœ— ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
                                    import traceback
                                    logger.error(traceback.format_exc())

                        db.conn.commit()
                    finally:
                        db.close()

            elif table_name == 'capsule_tags':
                records = supabase.download_tags(user_id)
            elif table_name == 'capsule_coordinates':
                records = supabase.download_coordinates(user_id)
            else:
                raise Exception(f"ä¸æ”¯æŒçš„è¡¨å: {table_name}")

            return jsonify({
                'success': True,
                'data': {
                    'records': records,
                    'deleted_ids': []
                }
            })

        except ImportError:
            raise Exception("Supabase SDK æœªå®‰è£…")
        except Exception as e:
            raise Exception(f"äº‘ç«¯ä¸‹è½½å¤±è´¥: {str(e)}")

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"ä»äº‘ç«¯ä¸‹è½½å¤±è´¥: {e}", 500)


# ============================================================
# Conflict Resolution Routes
# ============================================================

@sync_bp.route('/conflicts', methods=['GET'])
def get_conflicts():
    """
    è·å–æœªè§£å†³çš„å†²çªåˆ—è¡¨

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "conflicts": [...]
            }
        }
    """
    try:
        conn = sqlite3.connect(os.getenv('DATABASE_PATH', 'database/capsules.db').replace('sqlite:///', ''))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("""
            SELECT id, table_name, record_id, conflict_type, created_at
            FROM sync_conflicts
            WHERE resolved = 0
            ORDER BY created_at DESC
        """)

        conflicts = [dict(row) for row in cursor.fetchall()]
        conn.close()

        return jsonify({
            'success': True,
            'data': {
                'conflicts': conflicts,
                'count': len(conflicts)
            }
        })

    except Exception as e:
        raise APIError(f"è·å–å†²çªåˆ—è¡¨å¤±è´¥: {e}", 500)


@sync_bp.route('/resolve-conflict', methods=['POST'])
@token_required
def resolve_conflict_endpoint(current_user):
    """
    è§£å†³å†²çª

    è¯·æ±‚ä½“:
        {
            "conflict_id": 1,
            "resolution": "local"  // "local", "cloud", "merge"
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "message": "å†²çªå·²è§£å†³"
        }
    """
    try:
        data = request.get_json()

        if not data:
            raise APIError('è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', 400)

        conflict_id = data.get('conflict_id')
        resolution = data.get('resolution')

        if not all([conflict_id, resolution]):
            raise APIError('ç¼ºå°‘å¿…è¦å‚æ•°: conflict_id, resolution', 400)

        if resolution not in ['local', 'cloud', 'merge']:
            raise APIError('æ— æ•ˆçš„è§£å†³æ–¹æ¡ˆ', 400)

        sync_service = get_sync_service()
        success = sync_service.resolve_conflict(conflict_id, resolution)

        if success:
            return jsonify({
                'success': True,
                'message': 'å†²çªå·²è§£å†³'
            })
        else:
            raise APIError('è§£å†³å†²çªå¤±è´¥', 500)

    except APIError:
        raise
    except Exception as e:
        raise APIError(f"è§£å†³å†²çªå¤±è´¥: {e}", 500)


# ============================================================
# Phase B.4: Lightweight Sync API
# ============================================================

@sync_bp.route('/lightweight', methods=['POST'])
@token_required
def sync_metadata_lightweight(current_user):
    """
    è½»é‡çº§åŒæ­¥ï¼šä»…åŒæ­¥å…ƒæ•°æ® + é¢„è§ˆéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰

    Phase B.4 æ–°å¢åŠŸèƒ½ï¼šåˆ†ç¦»å…ƒæ•°æ®å’Œèµ„äº§åŒæ­¥

    è¯·æ±‚ä½“:
        {
            "include_previews": true,  // æ˜¯å¦è‡ªåŠ¨ä¸‹è½½é¢„è§ˆéŸ³é¢‘
            "force": false              // æ˜¯å¦å¼ºåˆ¶åŒæ­¥ï¼ˆå¿½ç•¥æœ¬åœ°ç¼“å­˜ï¼‰
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "synced_count": 10,
                "preview_downloaded": 5,
                "duration_seconds": 2.5,
                "errors": []
            }
        }
    """
    try:
        data = request.get_json() or {}
        include_previews = data.get('include_previews', True)
        force = data.get('force', False)
        capsule_ids = data.get('capsule_ids')  # è·å–æŒ‡å®šçš„èƒ¶å›Š ID åˆ—è¡¨

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ”„ è½»é‡çº§åŒæ­¥è¯·æ±‚")
        logger.info("=" * 60)
        logger.info(f"ç”¨æˆ·: {current_user.get('username')}")
        logger.info(f"åŒ…å«é¢„è§ˆéŸ³é¢‘: {include_previews}")
        logger.info(f"å¼ºåˆ¶åŒæ­¥: {force}")
        if capsule_ids:
            logger.info(f"æŒ‡å®šèƒ¶å›Š: {capsule_ids}")

        # è·å–ç”¨æˆ· ID
        user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

        if not user_id:
            raise APIError('ç”¨æˆ· ID ä¸å­˜åœ¨', 400)

        # è·å–åŒæ­¥æœåŠ¡å®ä¾‹
        sync_service = get_sync_service()

        # æ‰§è¡Œè½»é‡çº§åŒæ­¥
        result = sync_service.sync_metadata_lightweight(
            user_id=user_id,
            include_previews=include_previews,
            capsule_ids=capsule_ids  # ä¼ é€’æŒ‡å®šçš„èƒ¶å›Š ID åˆ—è¡¨
        )

        # åŒæ—¶ä¹ŸåŒæ­¥æ£±é•œé…ç½® (Phase C)
        try:
            sync_service.sync_prisms(user_id)
        except Exception as e:
            logger.warning(f"æ£±é•œåŒæ­¥å¤±è´¥ (éé˜»æ–­): {e}")

        if result['success']:
            logger.info(f"âœ… è½»é‡çº§åŒæ­¥æˆåŠŸ: {result['synced_count']} ä¸ªèƒ¶å›Š")
            return jsonify({
                'success': True,
                'data': {
                    'synced_count': result['synced_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            })
        else:
            logger.warning(f"âš ï¸  è½»é‡çº§åŒæ­¥éƒ¨åˆ†å¤±è´¥: {len(result['errors'])} ä¸ªé”™è¯¯")
            return jsonify({
                'success': False,
                'error': 'åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯',
                'data': {
                    'synced_count': result['synced_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            }), 207  # 207 Multi-Statusï¼ˆéƒ¨åˆ†æˆåŠŸï¼‰

    except APIError:
        raise
    except Exception as e:
        logger.error(f"è½»é‡çº§åŒæ­¥å¤±è´¥: {e}")
        raise APIError(f"è½»é‡çº§åŒæ­¥å¤±è´¥: {e}", 500)


@sync_bp.route('/upload-audio', methods=['POST'])
@token_required
def upload_audio_folders(current_user):
    """
    ä¸Šä¼ æœ¬åœ° Audio æ–‡ä»¶å¤¹ï¼ˆæ•´ä½“åŒæ­¥ç”¨ï¼‰
    è¯·æ±‚ä½“:
        {
            "capsule_ids": [1,2,3]  // å¯é€‰ï¼ŒæŒ‡å®šèƒ¶å›Š
        }
    """
    try:
        data = request.get_json() or {}
        capsule_ids = data.get('capsule_ids')

        user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))
        if not user_id:
            raise APIError('ç”¨æˆ· ID ä¸å­˜åœ¨', 400)

        sync_service = get_sync_service()
        result = sync_service.upload_audio_folders(
            user_id=user_id,
            capsule_ids=capsule_ids
        )

        if result['success']:
            return jsonify({'success': True, 'data': result})
        return jsonify({'success': False, 'error': 'éŸ³é¢‘ä¸Šä¼ å¤±è´¥', 'data': result}), 207
    except APIError:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼  Audio æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        raise APIError(f"ä¸Šä¼  Audio æ–‡ä»¶å¤¹å¤±è´¥: {e}", 500)


@sync_bp.route('/sync-tags', methods=['POST'])
@token_required
def sync_tags_only(current_user):
    """
    åªåŒæ­¥å…³é”®è¯æ•°æ®ï¼ˆcapsule_tagsï¼‰
    
    åŒå‘åŒæ­¥ï¼š
    1. ä¸Šä¼ æœ¬åœ°ä¿®æ”¹è¿‡çš„å…³é”®è¯åˆ°äº‘ç«¯
    2. ä¸‹è½½äº‘ç«¯æ›´æ–°çš„å…³é”®è¯åˆ°æœ¬åœ°
    
    åªåŒæ­¥æœ‰å˜åŒ–çš„æ•°æ®ï¼Œé€šè¿‡ updated_at æ¯”å¯¹
    """
    try:
        sync_service = get_sync_service()
        user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))
        if not user_id:
            raise APIError('ç”¨æˆ· ID ä¸å­˜åœ¨', 400)

        result = sync_service.sync_tags_only(user_id=user_id)

        if result['success']:
            logger.info(f"âœ… å…³é”®è¯åŒæ­¥æˆåŠŸ: ä¸Šä¼  {result.get('uploaded', 0)}, ä¸‹è½½ {result.get('downloaded', 0)}")
            return jsonify({'success': True, 'data': result})
        return jsonify({'success': False, 'error': 'å…³é”®è¯åŒæ­¥å¤±è´¥', 'data': result}), 207
    except APIError:
        raise
    except Exception as e:
        logger.error(f"å…³é”®è¯åŒæ­¥å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise APIError(f"å…³é”®è¯åŒæ­¥å¤±è´¥: {e}", 500)


@sync_bp.route('/upload-progress', methods=['GET'])
def get_upload_progress():
    """
    è·å–å•ä¸ªèƒ¶å›Šä¸Šä¼ è¿›åº¦
    Query å‚æ•°:
        capsule_id: èƒ¶å›Š ID
    """
    try:
        capsule_id = request.args.get('capsule_id', type=int)
        if not capsule_id:
            raise APIError('ç¼ºå°‘ capsule_id', 400)

        from sync_service import _get_upload_progress
        progress = _get_upload_progress(capsule_id)
        return jsonify({
            'success': True,
            'data': progress
        })
    except Exception as e:
        logger.error(f"è·å–ä¸Šä¼ è¿›åº¦å¤±è´¥: {e}")
        raise APIError(f"è·å–ä¸Šä¼ è¿›åº¦å¤±è´¥: {e}", 500)


@sync_bp.route('/download-only', methods=['POST'])
@token_required
def download_only(current_user):
    """
    ä»…ä¸‹è½½æ¨¡å¼ï¼šåªä»äº‘ç«¯ä¸‹è½½æ•°æ®ï¼Œä¸ä¸Šä¼ æœ¬åœ°å˜æ›´

    Phase G2 æ–°å¢åŠŸèƒ½ï¼šå¯åŠ¨åŒæ­¥ä¸“ç”¨

    è¯·æ±‚ä½“:
        {
            "include_previews": true  // æ˜¯å¦è‡ªåŠ¨ä¸‹è½½é¢„è§ˆéŸ³é¢‘
        }

    éœ€è¦è®¤è¯

    å“åº”:
        {
            "success": true,
            "data": {
                "downloaded_count": 10,
                "preview_downloaded": 5,
                "duration_seconds": 2.5,
                "errors": []
            }
        }
    """
    try:
        data = request.get_json() or {}
        include_previews = data.get('include_previews', True)

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ”„ ä»…ä¸‹è½½æ¨¡å¼ï¼ˆå¯åŠ¨åŒæ­¥ï¼‰")
        logger.info("=" * 60)
        logger.info(f"ç”¨æˆ·: {current_user.get('username')}")
        logger.info(f"åŒ…å«é¢„è§ˆéŸ³é¢‘: {include_previews}")
        logger.info("âš ï¸  è·³è¿‡æœ¬åœ°æ•°æ®ä¸Šä¼ ")

        # è·å–ç”¨æˆ· ID
        user_id = current_user.get('supabase_user_id') or str(current_user.get('id', ''))

        if not user_id:
            raise APIError('ç”¨æˆ· ID ä¸å­˜åœ¨', 400)

        # è·å–åŒæ­¥æœåŠ¡å®ä¾‹
        sync_service = get_sync_service()

        # æ‰§è¡Œä»…ä¸‹è½½åŒæ­¥
        result = sync_service.download_only(
            user_id=user_id,
            include_previews=include_previews
        )

        # åŒæ—¶ä¹ŸåŒæ­¥æ£±é•œé…ç½® (Phase C)
        try:
            sync_service.sync_prisms(user_id)
        except Exception as e:
            logger.warning(f"æ£±é•œåŒæ­¥å¤±è´¥ (éé˜»æ–­): {e}")

        if result['success']:
            logger.info(f"âœ… ä»…ä¸‹è½½æˆåŠŸ: {result['downloaded_count']} ä¸ªèƒ¶å›Š")
            return jsonify({
                'success': True,
                'data': {
                    'downloaded_count': result['downloaded_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            })
        else:
            logger.warning(f"âš ï¸  ä»…ä¸‹è½½éƒ¨åˆ†å¤±è´¥: {len(result['errors'])} ä¸ªé”™è¯¯")
            return jsonify({
                'success': False,
                'error': 'ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯',
                'data': {
                    'downloaded_count': result['downloaded_count'],
                    'preview_downloaded': result['preview_downloaded'],
                    'duration_seconds': result['duration_seconds'],
                    'errors': result['errors']
                }
            }), 207  # 207 Multi-Statusï¼ˆéƒ¨åˆ†æˆåŠŸï¼‰

    except APIError:
        raise
    except Exception as e:
        logger.error(f"ä»…ä¸‹è½½å¤±è´¥: {e}")
        raise APIError(f"ä»…ä¸‹è½½å¤±è´¥: {e}", 500)
